{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x13affebdad0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import Tuning\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils.Tuning import random_search_nn, random_search_td\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "housedata = torch.tensor(np.loadtxt('data\\\\readyhousedata.txt', delimiter=','), dtype=torch.float32)\n",
    "\n",
    "X = housedata[:, :-1]\n",
    "y = housedata[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_param_grid = {\n",
    "    'learning_rate': [0.1, 0.01, 0.001, 0.0001], \n",
    "    'epochs': [200, 400, 600],\n",
    "    'betas': [\n",
    "        (0.9, 0.999), \n",
    "        (0.85, 0.999),  \n",
    "        (0.95, 0.999),  \n",
    "        (0.9, 0.99),  \n",
    "        (0.85, 0.99),  \n",
    "        (0.95, 0.99), \n",
    "        (0.8, 0.999),  \n",
    "    ]\n",
    "}\n",
    "\n",
    "td_param_grid = {\n",
    "    'gamma': [0, 0.1, 0.2, 0.9],\n",
    "    'learning_rate': [0.1, 0.01, 0.001, 0.0001],\n",
    "    'epochs': [200, 400, 600],\n",
    "    'epsilon': [1e-5, 1e-6, 1e-7],\n",
    "    'betas': [\n",
    "        (0.9, 0.999), \n",
    "        (0.85, 0.999),  \n",
    "        (0.95, 0.999),  \n",
    "        (0.9, 0.99),  \n",
    "        (0.85, 0.99),  \n",
    "        (0.95, 0.99), \n",
    "        (0.8, 0.999),  \n",
    "    ]\n",
    "}\n",
    "\n",
    "grids = {\n",
    "    'td': td_param_grid,\n",
    "    'nn': nn_param_grid,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished. Final epoch loss: 862.6175965529221\n",
      "Training finished. Final epoch loss: 321.4159592848558\n",
      "Training finished. Final epoch loss: 1890.348407451923\n",
      "Training finished. Final epoch loss: 166.3489674788255\n",
      "Training finished. Final epoch loss: 197.99587513850287\n",
      "Training finished. Final epoch loss: 163.98760516826923\n",
      "Training finished. Final epoch loss: 168.12437615027795\n",
      "Training finished. Final epoch loss: 265.3518701700064\n",
      "Training finished. Final epoch loss: 199.97460321279672\n",
      "Training finished. Final epoch loss: 1757.8496633676382\n",
      "Training finished. Final epoch loss: 119.5244272672213\n",
      "Training finished. Final epoch loss: 134.63678470024695\n",
      "Training finished. Final epoch loss: 266.035586137038\n",
      "Training finished. Final epoch loss: 258.05468676640436\n",
      "Training finished. Final epoch loss: 615.2776753352239\n",
      "Training finished. Final epoch loss: 280.3808451432448\n",
      "Training finished. Final epoch loss: 485.4699246333196\n",
      "Training finished. Final epoch loss: 1601.6190631573018\n",
      "Training finished. Final epoch loss: 692.1141826923077\n",
      "Training finished. Final epoch loss: 48.384386429419884\n",
      "Training finished. Final epoch loss: 68.86131873497597\n",
      "Training finished. Final epoch loss: 194.58594292860764\n",
      "Training finished. Final epoch loss: 808.7147612938514\n",
      "Training finished. Final epoch loss: 498.2628047649677\n",
      "Training finished. Final epoch loss: 710.3000470674955\n",
      "Training finished. Final epoch loss: 212.19797779963568\n",
      "Training finished. Final epoch loss: 87.3338130070613\n",
      "Training finished. Final epoch loss: 339.15083782489484\n",
      "Training finished. Final epoch loss: 61.934108660771294\n",
      "Training finished. Final epoch loss: 218.82841007526105\n",
      "Training finished. Final epoch loss: 1140.8662731464092\n",
      "Training finished. Final epoch loss: 791.0104510967548\n",
      "Training finished. Final epoch loss: 189.20859439556415\n",
      "Training finished. Final epoch loss: 315.518187889686\n",
      "Training finished. Final epoch loss: 147.8714879842905\n",
      "Training finished. Final epoch loss: 195.68449460543118\n",
      "Training finished. Final epoch loss: 168.43672092144305\n",
      "Training finished. Final epoch loss: 176.19794786893405\n",
      "Training finished. Final epoch loss: 635.3815137423002\n",
      "Training finished. Final epoch loss: 159.87732982635498\n",
      "Training finished. Final epoch loss: 1208.1337115948018\n",
      "Training finished. Final epoch loss: 213.25039394085223\n",
      "Training finished. Final epoch loss: 259.7875844515287\n",
      "Training finished. Final epoch loss: 188.38418315007135\n",
      "Training finished. Final epoch loss: 167.1389783712534\n",
      "Training finished. Final epoch loss: 149.9936604133019\n",
      "Training finished. Final epoch loss: 907.1126556396484\n",
      "Training finished. Final epoch loss: 1586.5216498741736\n",
      "Training finished. Final epoch loss: 213.8546292231633\n",
      "Training finished. Final epoch loss: 201.6075289799617\n",
      "Training finished. Final epoch loss: 375.0494713416466\n",
      "Training finished. Final epoch loss: 134.91636643042932\n",
      "Training finished. Final epoch loss: 218.1023716559777\n",
      "Training finished. Final epoch loss: 1704.8071547288162\n",
      "Training finished. Final epoch loss: 1181.520716740535\n",
      "Training finished. Final epoch loss: 66.66779375076294\n",
      "Training finished. Final epoch loss: 418.91913003187915\n",
      "Training finished. Final epoch loss: 162.9377258007343\n",
      "Training finished. Final epoch loss: 207.98170823317307\n",
      "Training finished. Final epoch loss: 379.88838254488434\n",
      "Training finished. Final epoch loss: 684.4326327397273\n",
      "Training finished. Final epoch loss: 199.72112244826096\n",
      "Training finished. Final epoch loss: 2322.367714515099\n",
      "Training finished. Final epoch loss: 313.0314542330228\n",
      "Training finished. Final epoch loss: 63.33894128065843\n",
      "Training finished. Final epoch loss: 68.97283781491794\n",
      "Training finished. Final epoch loss: 159.3885854941148\n",
      "Training finished. Final epoch loss: 152.07836264830368\n",
      "Training finished. Final epoch loss: 453.307674407959\n",
      "Training finished. Final epoch loss: 655.4944722102239\n",
      "Training finished. Final epoch loss: 269.48351727999176\n",
      "Training finished. Final epoch loss: 81.90268094723041\n",
      "Training finished. Final epoch loss: 358.38889972980206\n",
      "Training finished. Final epoch loss: 201.07371374276968\n",
      "Training finished. Final epoch loss: 138.6203619150015\n",
      "Training finished. Final epoch loss: 666.6382769071139\n",
      "Training finished. Final epoch loss: 1343.6182579627405\n",
      "Training finished. Final epoch loss: 1600.2148766150842\n",
      "Training finished. Final epoch loss: 255.12558188805212\n",
      "Training finished. Final epoch loss: 172.46318186246432\n",
      "Training finished. Final epoch loss: 144.3228083390456\n",
      "Training finished. Final epoch loss: 151.48322560237006\n",
      "Training finished. Final epoch loss: 827.8096771240234\n",
      "Training finished. Final epoch loss: 494.59244361290564\n",
      "Training finished. Final epoch loss: 1758.0478697556716\n",
      "Training finished. Final epoch loss: 164.76403045654297\n",
      "Training finished. Final epoch loss: 89.86598975841815\n",
      "Training finished. Final epoch loss: 159.03284102219803\n",
      "Training finished. Final epoch loss: 220.4835979755108\n",
      "Training finished. Final epoch loss: 296.9541175548847\n",
      "Training finished. Final epoch loss: 81.1976996935331\n",
      "Training finished. Final epoch loss: 837.839229290302\n",
      "Training finished. Final epoch loss: 1764.172364455003\n",
      "Training finished. Final epoch loss: 168.0522152827336\n",
      "Training finished. Final epoch loss: 316.6927921588604\n",
      "Training finished. Final epoch loss: 195.32019578493558\n",
      "Training finished. Final epoch loss: 361.7982852642353\n",
      "Training finished. Final epoch loss: 186.67169193121103\n",
      "Training finished. Final epoch loss: 166.49822704608624\n",
      "Training finished. Final epoch loss: 56.329223082615776\n",
      "Validation RMSE for TD: 3.4682 for params: {'optimizer_type': 'adam', 'learning_rate': 0.0001, 'gamma': 0.1, 'epsilon': 1e-06, 'epochs': 600, 'betas': (0.8, 0.999)}\n",
      "Validation RMSE for TD: 3.0132 for params: {'optimizer_type': 'adam', 'learning_rate': 0.01, 'gamma': 0.1, 'epsilon': 1e-05, 'epochs': 200, 'betas': (0.9, 0.999)}\n",
      "Validation RMSE for TD: 2.6539 for params: {'optimizer_type': 'adam', 'learning_rate': 0.001, 'gamma': 0.1, 'epsilon': 1e-07, 'epochs': 600, 'betas': (0.95, 0.999)}\n",
      "Validation RMSE for TD: 2.8512 for params: {'optimizer_type': 'adam', 'learning_rate': 0.001, 'gamma': 0.9, 'epsilon': 1e-06, 'epochs': 600, 'betas': (0.95, 0.999)}\n",
      "Validation RMSE for TD: 3.6502 for params: {'optimizer_type': 'adam', 'learning_rate': 0.01, 'gamma': 0.9, 'epsilon': 1e-05, 'epochs': 200, 'betas': (0.9, 0.99)}\n",
      "Validation RMSE for TD: 3.2508 for params: {'optimizer_type': 'adam', 'learning_rate': 0.1, 'gamma': 0.2, 'epsilon': 1e-07, 'epochs': 200, 'betas': (0.85, 0.999)}\n",
      "Validation RMSE for TD: 2.6624 for params: {'optimizer_type': 'adam', 'learning_rate': 0.01, 'gamma': 0.9, 'epsilon': 1e-06, 'epochs': 200, 'betas': (0.95, 0.999)}\n",
      "Validation RMSE for TD: 2.9994 for params: {'optimizer_type': 'adam', 'learning_rate': 0.01, 'gamma': 0.9, 'epsilon': 1e-07, 'epochs': 400, 'betas': (0.95, 0.999)}\n",
      "Validation RMSE for TD: 2.6317 for params: {'optimizer_type': 'adam', 'learning_rate': 0.1, 'gamma': 0.2, 'epsilon': 1e-07, 'epochs': 600, 'betas': (0.85, 0.999)}\n",
      "Validation RMSE for TD: 2.8746 for params: {'optimizer_type': 'adam', 'learning_rate': 0.01, 'gamma': 0, 'epsilon': 1e-07, 'epochs': 200, 'betas': (0.9, 0.99)}\n",
      "Validation RMSE for TD: 2.7141 for params: {'optimizer_type': 'adam', 'learning_rate': 0.001, 'gamma': 0.9, 'epsilon': 1e-07, 'epochs': 400, 'betas': (0.9, 0.999)}\n",
      "Validation RMSE for TD: 4.0488 for params: {'optimizer_type': 'adam', 'learning_rate': 0.0001, 'gamma': 0.9, 'epsilon': 1e-05, 'epochs': 400, 'betas': (0.85, 0.99)}\n",
      "Validation RMSE for TD: 2.7897 for params: {'optimizer_type': 'adam', 'learning_rate': 0.01, 'gamma': 0.2, 'epsilon': 1e-06, 'epochs': 400, 'betas': (0.9, 0.99)}\n",
      "Validation RMSE for TD: 2.7516 for params: {'optimizer_type': 'adam', 'learning_rate': 0.01, 'gamma': 0.9, 'epsilon': 1e-06, 'epochs': 400, 'betas': (0.9, 0.99)}\n",
      "Validation RMSE for TD: 2.8130 for params: {'optimizer_type': 'adam', 'learning_rate': 0.001, 'gamma': 0.2, 'epsilon': 1e-06, 'epochs': 200, 'betas': (0.85, 0.999)}\n",
      "Validation RMSE for TD: 2.8476 for params: {'optimizer_type': 'adam', 'learning_rate': 0.1, 'gamma': 0.1, 'epsilon': 1e-05, 'epochs': 600, 'betas': (0.85, 0.999)}\n",
      "Validation RMSE for TD: 3.5533 for params: {'optimizer_type': 'adam', 'learning_rate': 0.0001, 'gamma': 0.1, 'epsilon': 1e-05, 'epochs': 600, 'betas': (0.9, 0.999)}\n",
      "Validation RMSE for TD: 2.6410 for params: {'optimizer_type': 'adam', 'learning_rate': 0.001, 'gamma': 0, 'epsilon': 1e-07, 'epochs': 600, 'betas': (0.9, 0.99)}\n",
      "Validation RMSE for TD: 2.7183 for params: {'optimizer_type': 'adam', 'learning_rate': 0.001, 'gamma': 0.2, 'epsilon': 1e-06, 'epochs': 200, 'betas': (0.9, 0.999)}\n",
      "Validation RMSE for TD: 2.7534 for params: {'optimizer_type': 'adam', 'learning_rate': 0.01, 'gamma': 0.9, 'epsilon': 1e-06, 'epochs': 400, 'betas': (0.95, 0.99)}\n",
      "Validation RMSE for TD: 2.8647 for params: {'optimizer_type': 'adam', 'learning_rate': 0.01, 'gamma': 0, 'epsilon': 1e-05, 'epochs': 600, 'betas': (0.95, 0.99)}\n",
      "Validation RMSE for TD: 3.1194 for params: {'optimizer_type': 'adam', 'learning_rate': 0.01, 'gamma': 0, 'epsilon': 1e-07, 'epochs': 400, 'betas': (0.8, 0.999)}\n",
      "Validation RMSE for TD: 2.9467 for params: {'optimizer_type': 'adam', 'learning_rate': 0.001, 'gamma': 0.1, 'epsilon': 1e-07, 'epochs': 200, 'betas': (0.9, 0.999)}\n",
      "Validation RMSE for TD: 3.1060 for params: {'optimizer_type': 'adam', 'learning_rate': 0.001, 'gamma': 0.2, 'epsilon': 1e-07, 'epochs': 200, 'betas': (0.8, 0.999)}\n",
      "Validation RMSE for TD: 2.7473 for params: {'optimizer_type': 'adam', 'learning_rate': 0.01, 'gamma': 0.2, 'epsilon': 1e-05, 'epochs': 400, 'betas': (0.8, 0.999)}\n",
      "Validation RMSE for TD: 2.6961 for params: {'optimizer_type': 'adam', 'learning_rate': 0.1, 'gamma': 0.1, 'epsilon': 1e-06, 'epochs': 200, 'betas': (0.95, 0.999)}\n",
      "Validation RMSE for TD: 3.7444 for params: {'optimizer_type': 'adam', 'learning_rate': 0.0001, 'gamma': 0.1, 'epsilon': 1e-06, 'epochs': 400, 'betas': (0.95, 0.999)}\n",
      "Validation RMSE for TD: 3.7156 for params: {'optimizer_type': 'adam', 'learning_rate': 0.001, 'gamma': 0.9, 'epsilon': 1e-05, 'epochs': 600, 'betas': (0.9, 0.99)}\n",
      "Validation RMSE for TD: 3.1463 for params: {'optimizer_type': 'adam', 'learning_rate': 0.1, 'gamma': 0.9, 'epsilon': 1e-07, 'epochs': 400, 'betas': (0.95, 0.999)}\n",
      "Validation RMSE for TD: 2.8008 for params: {'optimizer_type': 'adam', 'learning_rate': 0.1, 'gamma': 0.1, 'epsilon': 1e-07, 'epochs': 400, 'betas': (0.9, 0.99)}\n",
      "Validation RMSE for TD: 3.4878 for params: {'optimizer_type': 'adam', 'learning_rate': 0.0001, 'gamma': 0, 'epsilon': 1e-06, 'epochs': 600, 'betas': (0.9, 0.999)}\n",
      "Validation RMSE for TD: 2.5710 for params: {'optimizer_type': 'adam', 'learning_rate': 0.1, 'gamma': 0, 'epsilon': 1e-05, 'epochs': 400, 'betas': (0.85, 0.99)}\n",
      "Validation RMSE for TD: 2.7585 for params: {'optimizer_type': 'adam', 'learning_rate': 0.1, 'gamma': 0.9, 'epsilon': 1e-07, 'epochs': 200, 'betas': (0.9, 0.999)}\n",
      "Validation RMSE for TD: 3.9328 for params: {'optimizer_type': 'adam', 'learning_rate': 0.0001, 'gamma': 0.2, 'epsilon': 1e-07, 'epochs': 400, 'betas': (0.95, 0.999)}\n",
      "Validation RMSE for TD: 3.0398 for params: {'optimizer_type': 'adam', 'learning_rate': 0.01, 'gamma': 0, 'epsilon': 1e-06, 'epochs': 200, 'betas': (0.9, 0.999)}\n",
      "Validation RMSE for TD: 6.3545 for params: {'optimizer_type': 'adam', 'learning_rate': 0.0001, 'gamma': 0, 'epsilon': 1e-05, 'epochs': 200, 'betas': (0.85, 0.999)}\n",
      "Validation RMSE for TD: 6.3653 for params: {'optimizer_type': 'adam', 'learning_rate': 0.0001, 'gamma': 0.9, 'epsilon': 1e-07, 'epochs': 200, 'betas': (0.85, 0.99)}\n",
      "Validation RMSE for TD: 2.3784 for params: {'optimizer_type': 'adam', 'learning_rate': 0.1, 'gamma': 0.1, 'epsilon': 1e-07, 'epochs': 400, 'betas': (0.85, 0.99)}\n",
      "Validation RMSE for TD: 3.0401 for params: {'optimizer_type': 'adam', 'learning_rate': 0.001, 'gamma': 0.9, 'epsilon': 1e-06, 'epochs': 200, 'betas': (0.85, 0.99)}\n",
      "Validation RMSE for TD: 3.0057 for params: {'optimizer_type': 'adam', 'learning_rate': 0.01, 'gamma': 0, 'epsilon': 1e-07, 'epochs': 600, 'betas': (0.85, 0.999)}\n",
      "Validation RMSE for TD: 3.0458 for params: {'optimizer_type': 'adam', 'learning_rate': 0.01, 'gamma': 0.1, 'epsilon': 1e-05, 'epochs': 600, 'betas': (0.95, 0.99)}\n",
      "Validation RMSE for TD: 2.8757 for params: {'optimizer_type': 'adam', 'learning_rate': 0.001, 'gamma': 0.1, 'epsilon': 1e-05, 'epochs': 400, 'betas': (0.95, 0.99)}\n",
      "Validation RMSE for TD: 2.8848 for params: {'optimizer_type': 'adam', 'learning_rate': 0.1, 'gamma': 0.2, 'epsilon': 1e-05, 'epochs': 400, 'betas': (0.95, 0.999)}\n",
      "Validation RMSE for TD: 2.9813 for params: {'optimizer_type': 'adam', 'learning_rate': 0.001, 'gamma': 0.9, 'epsilon': 1e-07, 'epochs': 400, 'betas': (0.8, 0.999)}\n",
      "Validation RMSE for TD: 2.7417 for params: {'optimizer_type': 'adam', 'learning_rate': 0.001, 'gamma': 0.1, 'epsilon': 1e-07, 'epochs': 200, 'betas': (0.85, 0.99)}\n",
      "Validation RMSE for TD: 3.4265 for params: {'optimizer_type': 'adam', 'learning_rate': 0.1, 'gamma': 0, 'epsilon': 1e-07, 'epochs': 200, 'betas': (0.8, 0.999)}\n",
      "Validation RMSE for TD: 3.0344 for params: {'optimizer_type': 'adam', 'learning_rate': 0.01, 'gamma': 0.2, 'epsilon': 1e-07, 'epochs': 200, 'betas': (0.9, 0.99)}\n",
      "Validation RMSE for TD: 2.6384 for params: {'optimizer_type': 'adam', 'learning_rate': 0.01, 'gamma': 0.1, 'epsilon': 1e-06, 'epochs': 600, 'betas': (0.85, 0.99)}\n",
      "Validation RMSE for TD: 3.2590 for params: {'optimizer_type': 'adam', 'learning_rate': 0.0001, 'gamma': 0.1, 'epsilon': 1e-06, 'epochs': 600, 'betas': (0.9, 0.99)}\n",
      "Validation RMSE for TD: 6.2116 for params: {'optimizer_type': 'adam', 'learning_rate': 0.0001, 'gamma': 0, 'epsilon': 1e-06, 'epochs': 200, 'betas': (0.9, 0.99)}\n",
      "Validation RMSE for TD: 3.4961 for params: {'optimizer_type': 'adam', 'learning_rate': 0.0001, 'gamma': 0.2, 'epsilon': 1e-06, 'epochs': 600, 'betas': (0.95, 0.999)}\n",
      "Validation RMSE for TD: 2.9676 for params: {'optimizer_type': 'adam', 'learning_rate': 0.01, 'gamma': 0, 'epsilon': 1e-07, 'epochs': 200, 'betas': (0.95, 0.999)}\n",
      "Validation RMSE for TD: 2.7606 for params: {'optimizer_type': 'adam', 'learning_rate': 0.01, 'gamma': 0.2, 'epsilon': 1e-06, 'epochs': 600, 'betas': (0.9, 0.999)}\n",
      "Validation RMSE for TD: 2.8253 for params: {'optimizer_type': 'adam', 'learning_rate': 0.1, 'gamma': 0.9, 'epsilon': 1e-05, 'epochs': 600, 'betas': (0.85, 0.999)}\n",
      "Validation RMSE for TD: 3.5183 for params: {'optimizer_type': 'adam', 'learning_rate': 0.1, 'gamma': 0.2, 'epsilon': 1e-05, 'epochs': 200, 'betas': (0.85, 0.99)}\n",
      "Validation RMSE for TD: 2.6660 for params: {'optimizer_type': 'adam', 'learning_rate': 0.001, 'gamma': 0.1, 'epsilon': 1e-05, 'epochs': 400, 'betas': (0.85, 0.99)}\n",
      "Validation RMSE for TD: 2.8908 for params: {'optimizer_type': 'adam', 'learning_rate': 0.001, 'gamma': 0, 'epsilon': 1e-06, 'epochs': 400, 'betas': (0.95, 0.999)}\n",
      "Validation RMSE for TD: 4.0890 for params: {'optimizer_type': 'adam', 'learning_rate': 0.0001, 'gamma': 0.1, 'epsilon': 1e-07, 'epochs': 400, 'betas': (0.85, 0.999)}\n",
      "Validation RMSE for TD: 2.8678 for params: {'optimizer_type': 'adam', 'learning_rate': 0.01, 'gamma': 0, 'epsilon': 1e-05, 'epochs': 200, 'betas': (0.8, 0.999)}\n",
      "Validation RMSE for TD: 2.7820 for params: {'optimizer_type': 'adam', 'learning_rate': 0.01, 'gamma': 0.2, 'epsilon': 1e-06, 'epochs': 600, 'betas': (0.9, 0.999)}\n",
      "Validation RMSE for TD: 2.8021 for params: {'optimizer_type': 'adam', 'learning_rate': 0.01, 'gamma': 0.2, 'epsilon': 1e-07, 'epochs': 600, 'betas': (0.85, 0.99)}\n",
      "Validation RMSE for TD: 3.8218 for params: {'optimizer_type': 'adam', 'learning_rate': 0.0001, 'gamma': 0, 'epsilon': 1e-05, 'epochs': 400, 'betas': (0.85, 0.99)}\n",
      "Validation RMSE for TD: 6.5743 for params: {'optimizer_type': 'adam', 'learning_rate': 0.0001, 'gamma': 0.2, 'epsilon': 1e-05, 'epochs': 200, 'betas': (0.85, 0.99)}\n",
      "Validation RMSE for TD: 6.5468 for params: {'optimizer_type': 'adam', 'learning_rate': 0.0001, 'gamma': 0, 'epsilon': 1e-06, 'epochs': 200, 'betas': (0.95, 0.999)}\n",
      "Validation RMSE for TD: 4.7604 for params: {'optimizer_type': 'adam', 'learning_rate': 0.0001, 'gamma': 0.9, 'epsilon': 1e-06, 'epochs': 200, 'betas': (0.8, 0.999)}\n",
      "Validation RMSE for TD: 2.6882 for params: {'optimizer_type': 'adam', 'learning_rate': 0.01, 'gamma': 0.1, 'epsilon': 1e-06, 'epochs': 200, 'betas': (0.85, 0.99)}\n",
      "Validation RMSE for TD: 3.7598 for params: {'optimizer_type': 'adam', 'learning_rate': 0.0001, 'gamma': 0.9, 'epsilon': 1e-05, 'epochs': 600, 'betas': (0.85, 0.999)}\n",
      "Validation RMSE for TD: 2.4945 for params: {'optimizer_type': 'adam', 'learning_rate': 0.001, 'gamma': 0, 'epsilon': 1e-06, 'epochs': 600, 'betas': (0.9, 0.999)}\n",
      "Validation RMSE for TD: 2.9830 for params: {'optimizer_type': 'adam', 'learning_rate': 0.01, 'gamma': 0.9, 'epsilon': 1e-07, 'epochs': 600, 'betas': (0.85, 0.999)}\n",
      "Validation RMSE for TD: 2.9154 for params: {'optimizer_type': 'adam', 'learning_rate': 0.1, 'gamma': 0, 'epsilon': 1e-07, 'epochs': 400, 'betas': (0.9, 0.999)}\n",
      "Validation RMSE for TD: 6.3874 for params: {'optimizer_type': 'adam', 'learning_rate': 0.0001, 'gamma': 0.2, 'epsilon': 1e-05, 'epochs': 200, 'betas': (0.95, 0.99)}\n",
      "Validation RMSE for TD: 2.8800 for params: {'optimizer_type': 'adam', 'learning_rate': 0.001, 'gamma': 0, 'epsilon': 1e-07, 'epochs': 400, 'betas': (0.9, 0.999)}\n",
      "Validation RMSE for TD: 2.7783 for params: {'optimizer_type': 'adam', 'learning_rate': 0.001, 'gamma': 0.2, 'epsilon': 1e-07, 'epochs': 400, 'betas': (0.95, 0.99)}\n",
      "Validation RMSE for TD: 2.4569 for params: {'optimizer_type': 'adam', 'learning_rate': 0.1, 'gamma': 0.1, 'epsilon': 1e-06, 'epochs': 600, 'betas': (0.8, 0.999)}\n",
      "Validation RMSE for TD: 6.1016 for params: {'optimizer_type': 'adam', 'learning_rate': 0.0001, 'gamma': 0.1, 'epsilon': 1e-07, 'epochs': 200, 'betas': (0.95, 0.99)}\n",
      "Validation RMSE for TD: 3.2571 for params: {'optimizer_type': 'adam', 'learning_rate': 0.1, 'gamma': 0.2, 'epsilon': 1e-06, 'epochs': 400, 'betas': (0.95, 0.99)}\n",
      "Validation RMSE for TD: 3.8812 for params: {'optimizer_type': 'adam', 'learning_rate': 0.1, 'gamma': 0.9, 'epsilon': 1e-05, 'epochs': 600, 'betas': (0.8, 0.999)}\n",
      "Validation RMSE for TD: 2.7363 for params: {'optimizer_type': 'adam', 'learning_rate': 0.001, 'gamma': 0.2, 'epsilon': 1e-07, 'epochs': 600, 'betas': (0.9, 0.99)}\n",
      "Validation RMSE for TD: 3.1402 for params: {'optimizer_type': 'adam', 'learning_rate': 0.01, 'gamma': 0.1, 'epsilon': 1e-05, 'epochs': 200, 'betas': (0.85, 0.999)}\n",
      "Validation RMSE for TD: 2.8307 for params: {'optimizer_type': 'adam', 'learning_rate': 0.001, 'gamma': 0, 'epsilon': 1e-05, 'epochs': 600, 'betas': (0.95, 0.999)}\n",
      "Validation RMSE for TD: 3.6537 for params: {'optimizer_type': 'adam', 'learning_rate': 0.1, 'gamma': 0.9, 'epsilon': 1e-05, 'epochs': 200, 'betas': (0.9, 0.99)}\n",
      "Validation RMSE for TD: 3.5911 for params: {'optimizer_type': 'adam', 'learning_rate': 0.1, 'gamma': 0.9, 'epsilon': 1e-06, 'epochs': 200, 'betas': (0.95, 0.99)}\n",
      "Validation RMSE for TD: 4.0121 for params: {'optimizer_type': 'adam', 'learning_rate': 0.0001, 'gamma': 0, 'epsilon': 1e-07, 'epochs': 400, 'betas': (0.9, 0.99)}\n",
      "Validation RMSE for TD: 4.1432 for params: {'optimizer_type': 'adam', 'learning_rate': 0.0001, 'gamma': 0.2, 'epsilon': 1e-06, 'epochs': 400, 'betas': (0.9, 0.99)}\n",
      "Validation RMSE for TD: 3.7903 for params: {'optimizer_type': 'adam', 'learning_rate': 0.0001, 'gamma': 0.9, 'epsilon': 1e-07, 'epochs': 600, 'betas': (0.95, 0.99)}\n",
      "Validation RMSE for TD: 2.6614 for params: {'optimizer_type': 'adam', 'learning_rate': 0.001, 'gamma': 0.9, 'epsilon': 1e-07, 'epochs': 600, 'betas': (0.8, 0.999)}\n",
      "Validation RMSE for TD: 3.2856 for params: {'optimizer_type': 'adam', 'learning_rate': 0.1, 'gamma': 0, 'epsilon': 1e-05, 'epochs': 600, 'betas': (0.85, 0.99)}\n",
      "Validation RMSE for TD: 3.0422 for params: {'optimizer_type': 'adam', 'learning_rate': 0.01, 'gamma': 0.2, 'epsilon': 1e-06, 'epochs': 400, 'betas': (0.95, 0.99)}\n",
      "Validation RMSE for TD: 3.4096 for params: {'optimizer_type': 'adam', 'learning_rate': 0.1, 'gamma': 0.2, 'epsilon': 1e-07, 'epochs': 600, 'betas': (0.85, 0.99)}\n",
      "Validation RMSE for TD: 6.6342 for params: {'optimizer_type': 'adam', 'learning_rate': 0.0001, 'gamma': 0.1, 'epsilon': 1e-07, 'epochs': 200, 'betas': (0.85, 0.999)}\n",
      "Validation RMSE for TD: 2.6830 for params: {'optimizer_type': 'adam', 'learning_rate': 0.001, 'gamma': 0.1, 'epsilon': 1e-06, 'epochs': 400, 'betas': (0.85, 0.999)}\n",
      "Validation RMSE for TD: 2.9290 for params: {'optimizer_type': 'adam', 'learning_rate': 0.001, 'gamma': 0, 'epsilon': 1e-06, 'epochs': 600, 'betas': (0.95, 0.99)}\n",
      "Validation RMSE for TD: 4.0691 for params: {'optimizer_type': 'adam', 'learning_rate': 0.0001, 'gamma': 0.9, 'epsilon': 1e-05, 'epochs': 400, 'betas': (0.9, 0.999)}\n",
      "Validation RMSE for TD: 3.8549 for params: {'optimizer_type': 'adam', 'learning_rate': 0.1, 'gamma': 0.9, 'epsilon': 1e-05, 'epochs': 400, 'betas': (0.85, 0.999)}\n",
      "Validation RMSE for TD: 2.6068 for params: {'optimizer_type': 'adam', 'learning_rate': 0.01, 'gamma': 0.1, 'epsilon': 1e-05, 'epochs': 200, 'betas': (0.8, 0.999)}\n",
      "Validation RMSE for TD: 2.7637 for params: {'optimizer_type': 'adam', 'learning_rate': 0.1, 'gamma': 0, 'epsilon': 1e-06, 'epochs': 200, 'betas': (0.95, 0.99)}\n",
      "Validation RMSE for TD: 2.8085 for params: {'optimizer_type': 'adam', 'learning_rate': 0.1, 'gamma': 0, 'epsilon': 1e-05, 'epochs': 600, 'betas': (0.95, 0.999)}\n",
      "Validation RMSE for TD: 4.0177 for params: {'optimizer_type': 'adam', 'learning_rate': 0.0001, 'gamma': 0.2, 'epsilon': 1e-05, 'epochs': 400, 'betas': (0.8, 0.999)}\n",
      "Validation RMSE for TD: 2.7963 for params: {'optimizer_type': 'adam', 'learning_rate': 0.001, 'gamma': 0.2, 'epsilon': 1e-05, 'epochs': 600, 'betas': (0.95, 0.99)}\n",
      "Validation RMSE for TD: 2.8416 for params: {'optimizer_type': 'adam', 'learning_rate': 0.1, 'gamma': 0.1, 'epsilon': 1e-06, 'epochs': 400, 'betas': (0.8, 0.999)}\n",
      "Best hyperparameters for TD: {'optimizer_type': 'adam', 'learning_rate': 0.1, 'gamma': 0.1, 'epsilon': 1e-07, 'epochs': 400, 'betas': (0.85, 0.99)}, Best RMSE: 2.3784\n",
      "Time taken: 1740.8428 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "search_iterations = 100\n",
    "parameters = {}\n",
    "\n",
    "for model in ['td']:\n",
    "    param_grid = grids[model]\n",
    "    for optimizer in ['adam']:\n",
    "        t0 = time.time()\n",
    "        if model == 'td':\n",
    "            best_params = random_search_td(X_train, y_train, X_test, y_test, param_grid, search_iterations, optimizer)\n",
    "        elif model == 'nn':\n",
    "            best_params = random_search_td(X_train, y_train, X_test, y_test, param_grid, search_iterations, optimizer)\n",
    "        else:\n",
    "            raise Exception('Provide valid model')\n",
    "        t1 = time.time()\n",
    "        print(f\"Time taken: {t1-t0:.4f} seconds\")\n",
    "        parameters[f'{model}_{optimizer}'] = best_params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'optimizer_type': 'adam', 'learning_rate': 0.1, 'gamma': 0.2, 'epsilon': 1e-05, 'epochs': 400, 'betas': (0.95, 0.999)}\n"
     ]
    }
   ],
   "source": [
    "for i in parameters.values():\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

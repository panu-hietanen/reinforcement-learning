{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x270fc97dab0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import Tuning\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils.Tuning import random_search\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "housedata = torch.tensor(np.loadtxt('data\\\\readyhousedata.txt', delimiter=','), dtype=torch.float32)\n",
    "\n",
    "X = housedata[:, :-1]\n",
    "y = housedata[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_param_grid = {\n",
    "    'learning_rate': [0.1, 0.01, 0.001, 0.0001], \n",
    "    'epochs': [100, 200, 400, 800, 1600],\n",
    "    'betas': [\n",
    "        (0.9, 0.999), \n",
    "        (0.85, 0.999),  \n",
    "        (0.95, 0.999),  \n",
    "        (0.9, 0.99),  \n",
    "        (0.85, 0.99),  \n",
    "        (0.95, 0.99), \n",
    "        (0.8, 0.999),  \n",
    "        (0.9, 0.9999),  \n",
    "        (0.95, 0.9999),\n",
    "        (0.85, 0.9999)\n",
    "    ]\n",
    "}\n",
    "\n",
    "td_param_grid = {\n",
    "    'n_iter': [1e4, 1e5, 1e6],\n",
    "    'gamma': [0],\n",
    "    'learning_rate': [0.01, 0.001],\n",
    "    'epsilon': [1e-5, 1e-6, 1e-7],\n",
    "    'betas': [\n",
    "        (0.9, 0.999), \n",
    "        (0.85, 0.999),  \n",
    "        (0.95, 0.999),  \n",
    "        (0.9, 0.99),  \n",
    "        (0.85, 0.99),  \n",
    "        (0.95, 0.99), \n",
    "        (0.8, 0.999),  \n",
    "        (0.9, 0.9999),  \n",
    "        (0.95, 0.9999),\n",
    "        (0.85, 0.9999)\n",
    "    ]\n",
    "}\n",
    "\n",
    "grids = {\n",
    "    'td': td_param_grid,\n",
    "    'nn': nn_param_grid,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-07, n_iter=1000000.0, betas=(0.9, 0.9999)\n",
      "Ending optimization early at iteration 4041\n",
      "Validation RMSE for TD: 4.5071\n",
      "Iteration 2: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-06, n_iter=10000.0, betas=(0.95, 0.99)\n",
      "Ending optimization early at iteration 999\n",
      "Validation RMSE for TD: 8.8220\n",
      "Iteration 3: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-05, n_iter=100000.0, betas=(0.9, 0.999)\n",
      "Ending optimization early at iteration 3712\n",
      "Validation RMSE for TD: 8.7337\n",
      "Iteration 4: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-06, n_iter=1000000.0, betas=(0.9, 0.9999)\n",
      "Ending optimization early at iteration 1513\n",
      "Validation RMSE for TD: 8.7318\n",
      "Iteration 5: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-07, n_iter=10000.0, betas=(0.85, 0.99)\n",
      "Validation RMSE for TD: 8.7471\n",
      "Iteration 6: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-06, n_iter=10000.0, betas=(0.9, 0.9999)\n",
      "Validation RMSE for TD: 3.2657\n",
      "Iteration 7: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-06, n_iter=10000.0, betas=(0.85, 0.9999)\n",
      "Ending optimization early at iteration 5231\n",
      "Validation RMSE for TD: 3.0051\n",
      "Iteration 8: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-07, n_iter=100000.0, betas=(0.9, 0.99)\n",
      "Ending optimization early at iteration 8813\n",
      "Validation RMSE for TD: 2.6768\n",
      "Iteration 9: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-05, n_iter=10000.0, betas=(0.95, 0.99)\n",
      "Ending optimization early at iteration 2923\n",
      "Validation RMSE for TD: 8.7254\n",
      "Iteration 10: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-07, n_iter=10000.0, betas=(0.85, 0.99)\n",
      "Ending optimization early at iteration 707\n",
      "Validation RMSE for TD: 3.8260\n",
      "Iteration 11: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-06, n_iter=100000.0, betas=(0.9, 0.999)\n",
      "Ending optimization early at iteration 9947\n",
      "Validation RMSE for TD: 2.7025\n",
      "Iteration 12: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-05, n_iter=10000.0, betas=(0.95, 0.99)\n",
      "Ending optimization early at iteration 672\n",
      "Validation RMSE for TD: 4.6037\n",
      "Iteration 13: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-07, n_iter=1000000.0, betas=(0.95, 0.999)\n",
      "Ending optimization early at iteration 33378\n",
      "Validation RMSE for TD: 8.7229\n",
      "Iteration 14: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-05, n_iter=10000.0, betas=(0.95, 0.99)\n",
      "Ending optimization early at iteration 3970\n",
      "Validation RMSE for TD: 5.8711\n",
      "Iteration 15: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-07, n_iter=10000.0, betas=(0.95, 0.999)\n",
      "Validation RMSE for TD: 8.7823\n",
      "Iteration 16: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-07, n_iter=1000000.0, betas=(0.8, 0.999)\n",
      "Ending optimization early at iteration 2690\n",
      "Validation RMSE for TD: 3.3892\n",
      "Iteration 17: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-06, n_iter=1000000.0, betas=(0.85, 0.9999)\n",
      "Ending optimization early at iteration 4725\n",
      "Validation RMSE for TD: 8.7551\n",
      "Iteration 18: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-07, n_iter=1000000.0, betas=(0.85, 0.999)\n",
      "Ending optimization early at iteration 3748\n",
      "Validation RMSE for TD: 3.0455\n",
      "Iteration 19: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-05, n_iter=100000.0, betas=(0.95, 0.999)\n",
      "Ending optimization early at iteration 1406\n",
      "Validation RMSE for TD: 3.4873\n",
      "Iteration 20: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-07, n_iter=10000.0, betas=(0.95, 0.9999)\n",
      "Validation RMSE for TD: 3.6680\n",
      "Iteration 21: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-07, n_iter=100000.0, betas=(0.95, 0.9999)\n",
      "Ending optimization early at iteration 23187\n",
      "Validation RMSE for TD: 2.5669\n",
      "Iteration 22: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-07, n_iter=10000.0, betas=(0.9, 0.9999)\n",
      "Validation RMSE for TD: 8.7334\n",
      "Iteration 23: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-05, n_iter=10000.0, betas=(0.9, 0.999)\n",
      "Ending optimization early at iteration 4541\n",
      "Validation RMSE for TD: 3.3626\n",
      "Iteration 24: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-06, n_iter=10000.0, betas=(0.9, 0.999)\n",
      "Ending optimization early at iteration 54\n",
      "Validation RMSE for TD: 9.0021\n",
      "Iteration 25: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-05, n_iter=100000.0, betas=(0.9, 0.9999)\n",
      "Ending optimization early at iteration 3055\n",
      "Validation RMSE for TD: 4.2407\n",
      "Iteration 26: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-06, n_iter=100000.0, betas=(0.9, 0.9999)\n",
      "Ending optimization early at iteration 3204\n",
      "Validation RMSE for TD: 3.5227\n",
      "Iteration 27: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-05, n_iter=1000000.0, betas=(0.95, 0.999)\n",
      "Ending optimization early at iteration 473\n",
      "Validation RMSE for TD: 8.7209\n",
      "Iteration 28: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-05, n_iter=1000000.0, betas=(0.9, 0.9999)\n",
      "Ending optimization early at iteration 1624\n",
      "Validation RMSE for TD: 3.1061\n",
      "Iteration 29: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-06, n_iter=10000.0, betas=(0.9, 0.9999)\n",
      "Validation RMSE for TD: 8.7212\n",
      "Iteration 30: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-05, n_iter=10000.0, betas=(0.85, 0.9999)\n",
      "Ending optimization early at iteration 1644\n",
      "Validation RMSE for TD: 3.4401\n",
      "Iteration 31: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-06, n_iter=1000000.0, betas=(0.8, 0.999)\n",
      "Ending optimization early at iteration 7351\n",
      "Validation RMSE for TD: 2.7427\n",
      "Iteration 32: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-05, n_iter=1000000.0, betas=(0.95, 0.9999)\n",
      "Ending optimization early at iteration 2383\n",
      "Validation RMSE for TD: 2.8827\n",
      "Iteration 33: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-06, n_iter=100000.0, betas=(0.85, 0.9999)\n",
      "Ending optimization early at iteration 630\n",
      "Validation RMSE for TD: 4.0187\n",
      "Iteration 34: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-06, n_iter=10000.0, betas=(0.85, 0.99)\n",
      "Ending optimization early at iteration 1773\n",
      "Validation RMSE for TD: 4.1717\n",
      "Iteration 35: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-06, n_iter=1000000.0, betas=(0.9, 0.9999)\n",
      "Ending optimization early at iteration 12137\n",
      "Validation RMSE for TD: 8.7552\n",
      "Iteration 36: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-05, n_iter=10000.0, betas=(0.85, 0.99)\n",
      "Ending optimization early at iteration 950\n",
      "Validation RMSE for TD: 3.2501\n",
      "Iteration 37: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-05, n_iter=100000.0, betas=(0.85, 0.9999)\n",
      "Ending optimization early at iteration 1598\n",
      "Validation RMSE for TD: 8.7222\n",
      "Iteration 38: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-07, n_iter=10000.0, betas=(0.85, 0.99)\n",
      "Ending optimization early at iteration 5880\n",
      "Validation RMSE for TD: 3.3347\n",
      "Iteration 39: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-07, n_iter=1000000.0, betas=(0.95, 0.999)\n",
      "Ending optimization early at iteration 20687\n",
      "Validation RMSE for TD: 8.7215\n",
      "Iteration 40: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-07, n_iter=1000000.0, betas=(0.9, 0.99)\n",
      "Ending optimization early at iteration 19997\n",
      "Validation RMSE for TD: 8.7398\n",
      "Iteration 41: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-05, n_iter=100000.0, betas=(0.85, 0.999)\n",
      "Ending optimization early at iteration 3536\n",
      "Validation RMSE for TD: 8.7221\n",
      "Iteration 42: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-06, n_iter=100000.0, betas=(0.85, 0.99)\n",
      "Ending optimization early at iteration 2392\n",
      "Validation RMSE for TD: 4.3880\n",
      "Iteration 43: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-06, n_iter=100000.0, betas=(0.95, 0.99)\n",
      "Ending optimization early at iteration 1204\n",
      "Validation RMSE for TD: 3.8631\n",
      "Iteration 44: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-06, n_iter=100000.0, betas=(0.95, 0.999)\n",
      "Ending optimization early at iteration 6944\n",
      "Validation RMSE for TD: 8.8442\n",
      "Iteration 45: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-07, n_iter=10000.0, betas=(0.85, 0.9999)\n",
      "Validation RMSE for TD: 8.7212\n",
      "Iteration 46: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-05, n_iter=1000000.0, betas=(0.95, 0.99)\n",
      "Ending optimization early at iteration 5821\n",
      "Validation RMSE for TD: 3.1951\n",
      "Iteration 47: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-06, n_iter=100000.0, betas=(0.9, 0.999)\n",
      "Ending optimization early at iteration 1014\n",
      "Validation RMSE for TD: 5.2567\n",
      "Iteration 48: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-05, n_iter=100000.0, betas=(0.95, 0.9999)\n",
      "Ending optimization early at iteration 731\n",
      "Validation RMSE for TD: 8.7228\n",
      "Iteration 49: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-07, n_iter=1000000.0, betas=(0.9, 0.9999)\n",
      "Ending optimization early at iteration 2538\n",
      "Validation RMSE for TD: 8.7749\n",
      "Iteration 50: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-05, n_iter=1000000.0, betas=(0.85, 0.9999)\n",
      "Ending optimization early at iteration 1524\n",
      "Validation RMSE for TD: 8.7440\n",
      "Iteration 51: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-05, n_iter=100000.0, betas=(0.9, 0.999)\n",
      "Ending optimization early at iteration 567\n",
      "Validation RMSE for TD: 5.1961\n",
      "Iteration 52: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-06, n_iter=1000000.0, betas=(0.85, 0.999)\n",
      "Ending optimization early at iteration 4152\n",
      "Validation RMSE for TD: 8.7708\n",
      "Iteration 53: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-06, n_iter=1000000.0, betas=(0.95, 0.9999)\n",
      "Ending optimization early at iteration 10864\n",
      "Validation RMSE for TD: 8.7645\n",
      "Iteration 54: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-06, n_iter=10000.0, betas=(0.9, 0.99)\n",
      "Validation RMSE for TD: 8.7212\n",
      "Iteration 55: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-06, n_iter=1000000.0, betas=(0.95, 0.99)\n",
      "Ending optimization early at iteration 2188\n",
      "Validation RMSE for TD: 3.5072\n",
      "Iteration 56: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-07, n_iter=1000000.0, betas=(0.85, 0.999)\n",
      "Ending optimization early at iteration 3453\n",
      "Validation RMSE for TD: 4.7185\n",
      "Iteration 57: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-05, n_iter=100000.0, betas=(0.9, 0.999)\n",
      "Ending optimization early at iteration 5034\n",
      "Validation RMSE for TD: 8.7274\n",
      "Iteration 58: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-07, n_iter=100000.0, betas=(0.85, 0.99)\n",
      "Ending optimization early at iteration 4542\n",
      "Validation RMSE for TD: 4.0519\n",
      "Iteration 59: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-07, n_iter=1000000.0, betas=(0.8, 0.999)\n",
      "Ending optimization early at iteration 3325\n",
      "Validation RMSE for TD: 3.3216\n",
      "Iteration 60: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-07, n_iter=1000000.0, betas=(0.95, 0.99)\n",
      "Ending optimization early at iteration 6701\n",
      "Validation RMSE for TD: 8.7398\n",
      "Iteration 61: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-05, n_iter=100000.0, betas=(0.85, 0.9999)\n",
      "Ending optimization early at iteration 393\n",
      "Validation RMSE for TD: 4.1131\n",
      "Iteration 62: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-07, n_iter=1000000.0, betas=(0.85, 0.9999)\n",
      "Ending optimization early at iteration 3909\n",
      "Validation RMSE for TD: 3.4189\n",
      "Iteration 63: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-05, n_iter=10000.0, betas=(0.95, 0.9999)\n",
      "Ending optimization early at iteration 2502\n",
      "Validation RMSE for TD: 2.7959\n",
      "Iteration 64: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-06, n_iter=100000.0, betas=(0.9, 0.9999)\n",
      "Ending optimization early at iteration 5155\n",
      "Validation RMSE for TD: 8.8990\n",
      "Iteration 65: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-06, n_iter=100000.0, betas=(0.95, 0.999)\n",
      "Ending optimization early at iteration 4289\n",
      "Validation RMSE for TD: 4.5552\n",
      "Iteration 66: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-06, n_iter=1000000.0, betas=(0.9, 0.9999)\n",
      "Ending optimization early at iteration 9386\n",
      "Validation RMSE for TD: 4.3771\n",
      "Iteration 67: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-06, n_iter=1000000.0, betas=(0.85, 0.99)\n",
      "Ending optimization early at iteration 3380\n",
      "Validation RMSE for TD: 3.8220\n",
      "Iteration 68: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-06, n_iter=1000000.0, betas=(0.8, 0.999)\n",
      "Ending optimization early at iteration 9511\n",
      "Validation RMSE for TD: 2.9806\n",
      "Iteration 69: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-06, n_iter=100000.0, betas=(0.9, 0.9999)\n",
      "Ending optimization early at iteration 3017\n",
      "Validation RMSE for TD: 2.8887\n",
      "Iteration 70: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-05, n_iter=1000000.0, betas=(0.95, 0.9999)\n",
      "Ending optimization early at iteration 1278\n",
      "Validation RMSE for TD: 8.7215\n",
      "Iteration 71: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-05, n_iter=100000.0, betas=(0.9, 0.9999)\n",
      "Ending optimization early at iteration 2347\n",
      "Validation RMSE for TD: 3.1383\n",
      "Iteration 72: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-05, n_iter=100000.0, betas=(0.9, 0.999)\n",
      "Ending optimization early at iteration 2102\n",
      "Validation RMSE for TD: 8.7242\n",
      "Iteration 73: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-07, n_iter=1000000.0, betas=(0.9, 0.9999)\n",
      "Ending optimization early at iteration 16054\n",
      "Validation RMSE for TD: 8.8442\n",
      "Iteration 74: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-05, n_iter=10000.0, betas=(0.95, 0.99)\n",
      "Ending optimization early at iteration 3772\n",
      "Validation RMSE for TD: 8.7212\n",
      "Iteration 75: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-07, n_iter=10000.0, betas=(0.95, 0.999)\n",
      "Validation RMSE for TD: 8.7450\n",
      "Iteration 76: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-06, n_iter=1000000.0, betas=(0.8, 0.999)\n",
      "Ending optimization early at iteration 5917\n",
      "Validation RMSE for TD: 3.0245\n",
      "Iteration 77: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-05, n_iter=10000.0, betas=(0.85, 0.999)\n",
      "Ending optimization early at iteration 1273\n",
      "Validation RMSE for TD: 8.7222\n",
      "Iteration 78: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-06, n_iter=1000000.0, betas=(0.85, 0.999)\n",
      "Ending optimization early at iteration 11419\n",
      "Validation RMSE for TD: 3.0834\n",
      "Iteration 79: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-07, n_iter=100000.0, betas=(0.9, 0.999)\n",
      "Ending optimization early at iteration 6542\n",
      "Validation RMSE for TD: 2.8083\n",
      "Iteration 80: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-07, n_iter=100000.0, betas=(0.85, 0.99)\n",
      "Ending optimization early at iteration 45646\n",
      "Validation RMSE for TD: 8.7750\n",
      "Iteration 81: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-06, n_iter=100000.0, betas=(0.8, 0.999)\n",
      "Ending optimization early at iteration 5300\n",
      "Validation RMSE for TD: 3.4605\n",
      "Iteration 82: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-06, n_iter=1000000.0, betas=(0.85, 0.9999)\n",
      "Ending optimization early at iteration 4292\n",
      "Validation RMSE for TD: 3.4943\n",
      "Iteration 83: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-06, n_iter=100000.0, betas=(0.9, 0.9999)\n",
      "Ending optimization early at iteration 1423\n",
      "Validation RMSE for TD: 4.4714\n",
      "Iteration 84: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-06, n_iter=1000000.0, betas=(0.85, 0.9999)\n",
      "Ending optimization early at iteration 3215\n",
      "Validation RMSE for TD: 2.7346\n",
      "Iteration 85: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-06, n_iter=100000.0, betas=(0.85, 0.99)\n",
      "Ending optimization early at iteration 10793\n",
      "Validation RMSE for TD: 8.7644\n",
      "Iteration 86: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-06, n_iter=1000000.0, betas=(0.9, 0.9999)\n",
      "Ending optimization early at iteration 16382\n",
      "Validation RMSE for TD: 8.8442\n",
      "Iteration 87: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-07, n_iter=1000000.0, betas=(0.85, 0.999)\n",
      "Ending optimization early at iteration 10744\n",
      "Validation RMSE for TD: 3.0390\n",
      "Iteration 88: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-06, n_iter=100000.0, betas=(0.9, 0.99)\n",
      "Ending optimization early at iteration 1472\n",
      "Validation RMSE for TD: 5.3260\n",
      "Iteration 89: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-06, n_iter=1000000.0, betas=(0.8, 0.999)\n",
      "Ending optimization early at iteration 17923\n",
      "Validation RMSE for TD: 8.7228\n",
      "Iteration 90: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-07, n_iter=100000.0, betas=(0.9, 0.99)\n",
      "Ending optimization early at iteration 19036\n",
      "Validation RMSE for TD: 8.7439\n",
      "Iteration 91: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-06, n_iter=100000.0, betas=(0.95, 0.9999)\n",
      "Ending optimization early at iteration 431\n",
      "Validation RMSE for TD: 7.6240\n",
      "Iteration 92: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-06, n_iter=10000.0, betas=(0.9, 0.99)\n",
      "Ending optimization early at iteration 3006\n",
      "Validation RMSE for TD: 2.9061\n",
      "Iteration 93: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-07, n_iter=10000.0, betas=(0.9, 0.999)\n",
      "Ending optimization early at iteration 2868\n",
      "Validation RMSE for TD: 3.5631\n",
      "Iteration 94: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-06, n_iter=100000.0, betas=(0.8, 0.999)\n",
      "Ending optimization early at iteration 3618\n",
      "Validation RMSE for TD: 3.5411\n",
      "Iteration 95: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-07, n_iter=100000.0, betas=(0.8, 0.999)\n",
      "Ending optimization early at iteration 33386\n",
      "Validation RMSE for TD: 2.4977\n",
      "Iteration 96: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-07, n_iter=1000000.0, betas=(0.95, 0.9999)\n",
      "Ending optimization early at iteration 22330\n",
      "Validation RMSE for TD: 3.5306\n",
      "Iteration 97: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-05, n_iter=1000000.0, betas=(0.8, 0.999)\n",
      "Ending optimization early at iteration 1670\n",
      "Validation RMSE for TD: 8.7253\n",
      "Iteration 98: Training TD with optimizer=sgd, learning_rate=0.001, gamma=0, epsilon=1e-05, n_iter=1000000.0, betas=(0.95, 0.99)\n",
      "Ending optimization early at iteration 263\n",
      "Validation RMSE for TD: 6.2795\n",
      "Iteration 99: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-07, n_iter=1000000.0, betas=(0.9, 0.999)\n",
      "Ending optimization early at iteration 3923\n",
      "Validation RMSE for TD: 8.7607\n",
      "Iteration 100: Training TD with optimizer=sgd, learning_rate=0.01, gamma=0, epsilon=1e-05, n_iter=10000.0, betas=(0.85, 0.99)\n",
      "Ending optimization early at iteration 2595\n",
      "Validation RMSE for TD: 8.7864\n",
      "Best hyperparameters for TD: {'optimizer_type': 'sgd', 'learning_rate': 0.001, 'gamma': 0, 'epsilon': 1e-07, 'n_iter': 100000.0, 'betas': (0.8, 0.999)}, Best RMSE: 2.4977\n",
      "Iteration 1: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-07, n_iter=100000.0, betas=(0.95, 0.99)\n",
      "Ending optimization early at iteration 11155\n",
      "Validation RMSE for TD: 3.3789\n",
      "Iteration 2: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-05, n_iter=100000.0, betas=(0.85, 0.999)\n",
      "Ending optimization early at iteration 2737\n",
      "Validation RMSE for TD: 3.7906\n",
      "Iteration 3: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-06, n_iter=100000.0, betas=(0.95, 0.9999)\n",
      "Ending optimization early at iteration 4592\n",
      "Validation RMSE for TD: 4.1385\n",
      "Iteration 4: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-06, n_iter=100000.0, betas=(0.85, 0.99)\n",
      "Ending optimization early at iteration 735\n",
      "Validation RMSE for TD: 6.7374\n",
      "Iteration 5: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-06, n_iter=10000.0, betas=(0.9, 0.99)\n",
      "Ending optimization early at iteration 2061\n",
      "Validation RMSE for TD: 3.7389\n",
      "Iteration 6: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-07, n_iter=1000000.0, betas=(0.95, 0.9999)\n",
      "Ending optimization early at iteration 6754\n",
      "Validation RMSE for TD: 3.3178\n",
      "Iteration 7: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-06, n_iter=100000.0, betas=(0.85, 0.9999)\n",
      "Ending optimization early at iteration 6198\n",
      "Validation RMSE for TD: 3.1376\n",
      "Iteration 8: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-06, n_iter=1000000.0, betas=(0.85, 0.999)\n",
      "Ending optimization early at iteration 984\n",
      "Validation RMSE for TD: 3.5603\n",
      "Iteration 9: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-06, n_iter=1000000.0, betas=(0.9, 0.99)\n",
      "Ending optimization early at iteration 3312\n",
      "Validation RMSE for TD: 3.6312\n",
      "Iteration 10: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-06, n_iter=100000.0, betas=(0.85, 0.99)\n",
      "Ending optimization early at iteration 4439\n",
      "Validation RMSE for TD: 4.2570\n",
      "Iteration 11: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-06, n_iter=10000.0, betas=(0.9, 0.99)\n",
      "Ending optimization early at iteration 1229\n",
      "Validation RMSE for TD: 4.3957\n",
      "Iteration 12: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-06, n_iter=1000000.0, betas=(0.95, 0.9999)\n",
      "Ending optimization early at iteration 1487\n",
      "Validation RMSE for TD: 4.6371\n",
      "Iteration 13: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-07, n_iter=10000.0, betas=(0.95, 0.9999)\n",
      "Validation RMSE for TD: 3.1748\n",
      "Iteration 14: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-07, n_iter=10000.0, betas=(0.85, 0.999)\n",
      "Ending optimization early at iteration 7042\n",
      "Validation RMSE for TD: 4.1935\n",
      "Iteration 15: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-07, n_iter=1000000.0, betas=(0.9, 0.9999)\n",
      "Ending optimization early at iteration 23916\n",
      "Validation RMSE for TD: 2.9176\n",
      "Iteration 16: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-07, n_iter=10000.0, betas=(0.9, 0.99)\n",
      "Ending optimization early at iteration 4110\n",
      "Validation RMSE for TD: 3.9710\n",
      "Iteration 17: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-06, n_iter=1000000.0, betas=(0.9, 0.999)\n",
      "Ending optimization early at iteration 2047\n",
      "Validation RMSE for TD: 3.6358\n",
      "Iteration 18: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-07, n_iter=1000000.0, betas=(0.9, 0.999)\n",
      "Ending optimization early at iteration 19755\n",
      "Validation RMSE for TD: 3.1691\n",
      "Iteration 19: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-05, n_iter=10000.0, betas=(0.9, 0.999)\n",
      "Ending optimization early at iteration 229\n",
      "Validation RMSE for TD: 9.4191\n",
      "Iteration 20: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-07, n_iter=1000000.0, betas=(0.9, 0.99)\n",
      "Ending optimization early at iteration 24138\n",
      "Validation RMSE for TD: 2.8683\n",
      "Iteration 21: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-05, n_iter=10000.0, betas=(0.85, 0.999)\n",
      "Ending optimization early at iteration 1783\n",
      "Validation RMSE for TD: 3.0309\n",
      "Iteration 22: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-05, n_iter=10000.0, betas=(0.9, 0.99)\n",
      "Ending optimization early at iteration 554\n",
      "Validation RMSE for TD: 6.7188\n",
      "Iteration 23: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-07, n_iter=10000.0, betas=(0.85, 0.999)\n",
      "Validation RMSE for TD: 3.3833\n",
      "Iteration 24: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-06, n_iter=10000.0, betas=(0.8, 0.999)\n",
      "Ending optimization early at iteration 4027\n",
      "Validation RMSE for TD: 3.0246\n",
      "Iteration 25: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-06, n_iter=100000.0, betas=(0.95, 0.999)\n",
      "Ending optimization early at iteration 347\n",
      "Validation RMSE for TD: 8.6972\n",
      "Iteration 26: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-06, n_iter=1000000.0, betas=(0.85, 0.9999)\n",
      "Ending optimization early at iteration 4291\n",
      "Validation RMSE for TD: 3.4773\n",
      "Iteration 27: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-07, n_iter=100000.0, betas=(0.9, 0.999)\n",
      "Ending optimization early at iteration 11176\n",
      "Validation RMSE for TD: 3.1735\n",
      "Iteration 28: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-06, n_iter=100000.0, betas=(0.9, 0.9999)\n",
      "Ending optimization early at iteration 5057\n",
      "Validation RMSE for TD: 3.1196\n",
      "Iteration 29: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-07, n_iter=1000000.0, betas=(0.9, 0.9999)\n",
      "Ending optimization early at iteration 15174\n",
      "Validation RMSE for TD: 2.9849\n",
      "Iteration 30: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-05, n_iter=10000.0, betas=(0.85, 0.9999)\n",
      "Ending optimization early at iteration 2072\n",
      "Validation RMSE for TD: 4.2548\n",
      "Iteration 31: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-07, n_iter=1000000.0, betas=(0.8, 0.999)\n",
      "Ending optimization early at iteration 6377\n",
      "Validation RMSE for TD: 2.9894\n",
      "Iteration 32: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-07, n_iter=1000000.0, betas=(0.85, 0.999)\n",
      "Ending optimization early at iteration 4797\n",
      "Validation RMSE for TD: 3.3500\n",
      "Iteration 33: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-05, n_iter=100000.0, betas=(0.8, 0.999)\n",
      "Ending optimization early at iteration 986\n",
      "Validation RMSE for TD: 3.8713\n",
      "Iteration 34: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-06, n_iter=100000.0, betas=(0.95, 0.9999)\n",
      "Ending optimization early at iteration 10003\n",
      "Validation RMSE for TD: 2.7752\n",
      "Iteration 35: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-07, n_iter=1000000.0, betas=(0.95, 0.9999)\n",
      "Ending optimization early at iteration 12729\n",
      "Validation RMSE for TD: 2.8487\n",
      "Iteration 36: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-06, n_iter=1000000.0, betas=(0.85, 0.9999)\n",
      "Ending optimization early at iteration 2957\n",
      "Validation RMSE for TD: 3.6234\n",
      "Iteration 37: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-07, n_iter=100000.0, betas=(0.9, 0.999)\n",
      "Ending optimization early at iteration 9221\n",
      "Validation RMSE for TD: 3.0975\n",
      "Iteration 38: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-07, n_iter=100000.0, betas=(0.85, 0.999)\n",
      "Ending optimization early at iteration 16798\n",
      "Validation RMSE for TD: 2.9374\n",
      "Iteration 39: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-06, n_iter=100000.0, betas=(0.95, 0.9999)\n",
      "Ending optimization early at iteration 11515\n",
      "Validation RMSE for TD: 3.1721\n",
      "Iteration 40: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-07, n_iter=100000.0, betas=(0.9, 0.9999)\n",
      "Ending optimization early at iteration 17710\n",
      "Validation RMSE for TD: 3.1349\n",
      "Iteration 41: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-05, n_iter=10000.0, betas=(0.95, 0.999)\n",
      "Ending optimization early at iteration 2390\n",
      "Validation RMSE for TD: 4.0566\n",
      "Iteration 42: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-05, n_iter=1000000.0, betas=(0.95, 0.999)\n",
      "Ending optimization early at iteration 259\n",
      "Validation RMSE for TD: 4.9413\n",
      "Iteration 43: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-06, n_iter=100000.0, betas=(0.85, 0.999)\n",
      "Ending optimization early at iteration 15574\n",
      "Validation RMSE for TD: 2.6672\n",
      "Iteration 44: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-05, n_iter=1000000.0, betas=(0.85, 0.9999)\n",
      "Ending optimization early at iteration 1885\n",
      "Validation RMSE for TD: 4.3465\n",
      "Iteration 45: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-07, n_iter=10000.0, betas=(0.9, 0.999)\n",
      "Ending optimization early at iteration 8048\n",
      "Validation RMSE for TD: 2.8959\n",
      "Iteration 46: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-05, n_iter=10000.0, betas=(0.85, 0.99)\n",
      "Ending optimization early at iteration 794\n",
      "Validation RMSE for TD: 6.7235\n",
      "Iteration 47: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-05, n_iter=10000.0, betas=(0.85, 0.999)\n",
      "Ending optimization early at iteration 685\n",
      "Validation RMSE for TD: 6.4756\n",
      "Iteration 48: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-05, n_iter=1000000.0, betas=(0.95, 0.9999)\n",
      "Ending optimization early at iteration 290\n",
      "Validation RMSE for TD: 9.6562\n",
      "Iteration 49: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-07, n_iter=1000000.0, betas=(0.9, 0.99)\n",
      "Ending optimization early at iteration 9259\n",
      "Validation RMSE for TD: 2.9925\n",
      "Iteration 50: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-05, n_iter=1000000.0, betas=(0.85, 0.999)\n",
      "Ending optimization early at iteration 1256\n",
      "Validation RMSE for TD: 5.2104\n",
      "Iteration 51: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-05, n_iter=10000.0, betas=(0.8, 0.999)\n",
      "Ending optimization early at iteration 1349\n",
      "Validation RMSE for TD: 4.6713\n",
      "Iteration 52: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-07, n_iter=100000.0, betas=(0.9, 0.9999)\n",
      "Ending optimization early at iteration 2411\n",
      "Validation RMSE for TD: 3.3191\n",
      "Iteration 53: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-06, n_iter=10000.0, betas=(0.85, 0.9999)\n",
      "Ending optimization early at iteration 2033\n",
      "Validation RMSE for TD: 3.7187\n",
      "Iteration 54: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-05, n_iter=10000.0, betas=(0.95, 0.999)\n",
      "Ending optimization early at iteration 1777\n",
      "Validation RMSE for TD: 4.4713\n",
      "Iteration 55: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-07, n_iter=1000000.0, betas=(0.9, 0.99)\n",
      "Ending optimization early at iteration 17369\n",
      "Validation RMSE for TD: 2.7636\n",
      "Iteration 56: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-05, n_iter=1000000.0, betas=(0.9, 0.99)\n",
      "Ending optimization early at iteration 2308\n",
      "Validation RMSE for TD: 3.9041\n",
      "Iteration 57: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-07, n_iter=10000.0, betas=(0.9, 0.99)\n",
      "Validation RMSE for TD: 3.7780\n",
      "Iteration 58: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-06, n_iter=100000.0, betas=(0.9, 0.999)\n",
      "Ending optimization early at iteration 2182\n",
      "Validation RMSE for TD: 3.9528\n",
      "Iteration 59: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-07, n_iter=100000.0, betas=(0.95, 0.999)\n",
      "Ending optimization early at iteration 9484\n",
      "Validation RMSE for TD: 2.9900\n",
      "Iteration 60: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-07, n_iter=100000.0, betas=(0.85, 0.9999)\n",
      "Ending optimization early at iteration 3002\n",
      "Validation RMSE for TD: 3.0915\n",
      "Iteration 61: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-06, n_iter=10000.0, betas=(0.8, 0.999)\n",
      "Ending optimization early at iteration 732\n",
      "Validation RMSE for TD: 6.1082\n",
      "Iteration 62: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-07, n_iter=100000.0, betas=(0.9, 0.999)\n",
      "Ending optimization early at iteration 22382\n",
      "Validation RMSE for TD: 3.1387\n",
      "Iteration 63: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-06, n_iter=1000000.0, betas=(0.9, 0.999)\n",
      "Ending optimization early at iteration 416\n",
      "Validation RMSE for TD: 4.7668\n",
      "Iteration 64: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-05, n_iter=100000.0, betas=(0.9, 0.999)\n",
      "Ending optimization early at iteration 1186\n",
      "Validation RMSE for TD: 5.8705\n",
      "Iteration 65: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-05, n_iter=1000000.0, betas=(0.9, 0.99)\n",
      "Ending optimization early at iteration 1896\n",
      "Validation RMSE for TD: 4.0770\n",
      "Iteration 66: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-05, n_iter=100000.0, betas=(0.9, 0.9999)\n",
      "Ending optimization early at iteration 236\n",
      "Validation RMSE for TD: 7.7279\n",
      "Iteration 67: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-07, n_iter=1000000.0, betas=(0.9, 0.99)\n",
      "Ending optimization early at iteration 5058\n",
      "Validation RMSE for TD: 3.2374\n",
      "Iteration 68: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-05, n_iter=100000.0, betas=(0.95, 0.99)\n",
      "Ending optimization early at iteration 885\n",
      "Validation RMSE for TD: 5.0639\n",
      "Iteration 69: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-05, n_iter=10000.0, betas=(0.85, 0.99)\n",
      "Ending optimization early at iteration 1619\n",
      "Validation RMSE for TD: 4.2414\n",
      "Iteration 70: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-05, n_iter=10000.0, betas=(0.95, 0.9999)\n",
      "Ending optimization early at iteration 4932\n",
      "Validation RMSE for TD: 3.3913\n",
      "Iteration 71: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-07, n_iter=100000.0, betas=(0.8, 0.999)\n",
      "Ending optimization early at iteration 21139\n",
      "Validation RMSE for TD: 2.7121\n",
      "Iteration 72: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-05, n_iter=10000.0, betas=(0.95, 0.9999)\n",
      "Ending optimization early at iteration 4216\n",
      "Validation RMSE for TD: 3.3323\n",
      "Iteration 73: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-05, n_iter=100000.0, betas=(0.9, 0.9999)\n",
      "Ending optimization early at iteration 2113\n",
      "Validation RMSE for TD: 4.3766\n",
      "Iteration 74: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-05, n_iter=1000000.0, betas=(0.9, 0.99)\n",
      "Ending optimization early at iteration 3774\n",
      "Validation RMSE for TD: 3.6301\n",
      "Iteration 75: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-06, n_iter=100000.0, betas=(0.9, 0.9999)\n",
      "Ending optimization early at iteration 3833\n",
      "Validation RMSE for TD: 2.8398\n",
      "Iteration 76: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-05, n_iter=100000.0, betas=(0.9, 0.9999)\n",
      "Ending optimization early at iteration 2455\n",
      "Validation RMSE for TD: 3.1480\n",
      "Iteration 77: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-05, n_iter=10000.0, betas=(0.9, 0.999)\n",
      "Ending optimization early at iteration 810\n",
      "Validation RMSE for TD: 7.1648\n",
      "Iteration 78: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-07, n_iter=100000.0, betas=(0.9, 0.99)\n",
      "Ending optimization early at iteration 2342\n",
      "Validation RMSE for TD: 3.7375\n",
      "Iteration 79: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-05, n_iter=1000000.0, betas=(0.85, 0.999)\n",
      "Ending optimization early at iteration 1260\n",
      "Validation RMSE for TD: 5.4216\n",
      "Iteration 80: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-05, n_iter=10000.0, betas=(0.8, 0.999)\n",
      "Ending optimization early at iteration 201\n",
      "Validation RMSE for TD: 5.8536\n",
      "Iteration 81: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-07, n_iter=100000.0, betas=(0.9, 0.999)\n",
      "Ending optimization early at iteration 4323\n",
      "Validation RMSE for TD: 3.2551\n",
      "Iteration 82: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-05, n_iter=1000000.0, betas=(0.8, 0.999)\n",
      "Ending optimization early at iteration 4270\n",
      "Validation RMSE for TD: 3.0280\n",
      "Iteration 83: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-06, n_iter=100000.0, betas=(0.8, 0.999)\n",
      "Ending optimization early at iteration 143\n",
      "Validation RMSE for TD: 6.4397\n",
      "Iteration 84: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-07, n_iter=1000000.0, betas=(0.95, 0.9999)\n",
      "Ending optimization early at iteration 4492\n",
      "Validation RMSE for TD: 3.3045\n",
      "Iteration 85: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-07, n_iter=10000.0, betas=(0.8, 0.999)\n",
      "Validation RMSE for TD: 3.0199\n",
      "Iteration 86: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-07, n_iter=10000.0, betas=(0.8, 0.999)\n",
      "Ending optimization early at iteration 857\n",
      "Validation RMSE for TD: 5.9124\n",
      "Iteration 87: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-05, n_iter=1000000.0, betas=(0.85, 0.999)\n",
      "Ending optimization early at iteration 1268\n",
      "Validation RMSE for TD: 4.8816\n",
      "Iteration 88: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-05, n_iter=10000.0, betas=(0.85, 0.999)\n",
      "Ending optimization early at iteration 398\n",
      "Validation RMSE for TD: 7.5234\n",
      "Iteration 89: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-06, n_iter=100000.0, betas=(0.9, 0.999)\n",
      "Ending optimization early at iteration 219\n",
      "Validation RMSE for TD: 7.0401\n",
      "Iteration 90: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-07, n_iter=100000.0, betas=(0.9, 0.99)\n",
      "Ending optimization early at iteration 14799\n",
      "Validation RMSE for TD: 2.6957\n",
      "Iteration 91: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-06, n_iter=1000000.0, betas=(0.95, 0.99)\n",
      "Ending optimization early at iteration 2002\n",
      "Validation RMSE for TD: 4.0636\n",
      "Iteration 92: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-07, n_iter=10000.0, betas=(0.95, 0.9999)\n",
      "Ending optimization early at iteration 7669\n",
      "Validation RMSE for TD: 2.8374\n",
      "Iteration 93: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-06, n_iter=10000.0, betas=(0.9, 0.99)\n",
      "Ending optimization early at iteration 656\n",
      "Validation RMSE for TD: 3.6435\n",
      "Iteration 94: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-06, n_iter=100000.0, betas=(0.85, 0.99)\n",
      "Ending optimization early at iteration 5470\n",
      "Validation RMSE for TD: 3.0413\n",
      "Iteration 95: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-05, n_iter=10000.0, betas=(0.85, 0.99)\n",
      "Ending optimization early at iteration 482\n",
      "Validation RMSE for TD: 4.6183\n",
      "Iteration 96: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-05, n_iter=1000000.0, betas=(0.85, 0.9999)\n",
      "Ending optimization early at iteration 4746\n",
      "Validation RMSE for TD: 4.0820\n",
      "Iteration 97: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-06, n_iter=10000.0, betas=(0.95, 0.999)\n",
      "Ending optimization early at iteration 1710\n",
      "Validation RMSE for TD: 4.3564\n",
      "Iteration 98: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-07, n_iter=1000000.0, betas=(0.95, 0.9999)\n",
      "Ending optimization early at iteration 10790\n",
      "Validation RMSE for TD: 3.1138\n",
      "Iteration 99: Training TD with optimizer=adam, learning_rate=0.01, gamma=0, epsilon=1e-05, n_iter=10000.0, betas=(0.8, 0.999)\n",
      "Ending optimization early at iteration 407\n",
      "Validation RMSE for TD: 4.0878\n",
      "Iteration 100: Training TD with optimizer=adam, learning_rate=0.001, gamma=0, epsilon=1e-05, n_iter=10000.0, betas=(0.95, 0.999)\n",
      "Ending optimization early at iteration 362\n",
      "Validation RMSE for TD: 8.4166\n",
      "Best hyperparameters for TD: {'optimizer_type': 'adam', 'learning_rate': 0.001, 'gamma': 0, 'epsilon': 1e-06, 'n_iter': 100000.0, 'betas': (0.85, 0.999)}, Best RMSE: 2.6672\n",
      "Iteration 1: Training NN with optimizer=sgd, learning_rate=0.1, epochs=100, betas=(0.85, 0.9999)\n",
      "Validation RMSE: 104.6652\n",
      "Iteration 2: Training NN with optimizer=sgd, learning_rate=0.01, epochs=100, betas=(0.85, 0.9999)\n",
      "Validation RMSE: 5.3578\n",
      "Iteration 3: Training NN with optimizer=sgd, learning_rate=0.001, epochs=100, betas=(0.95, 0.99)\n",
      "Validation RMSE: 5.9733\n",
      "Iteration 4: Training NN with optimizer=sgd, learning_rate=0.0001, epochs=200, betas=(0.9, 0.9999)\n",
      "Validation RMSE: 10.8497\n",
      "Iteration 5: Training NN with optimizer=sgd, learning_rate=0.0001, epochs=800, betas=(0.8, 0.999)\n",
      "Validation RMSE: 6.6599\n",
      "Iteration 6: Training NN with optimizer=sgd, learning_rate=0.01, epochs=100, betas=(0.9, 0.99)\n",
      "Validation RMSE: 4.5385\n",
      "Iteration 7: Training NN with optimizer=sgd, learning_rate=0.001, epochs=800, betas=(0.9, 0.9999)\n",
      "Validation RMSE: 3.2643\n",
      "Iteration 8: Training NN with optimizer=sgd, learning_rate=0.01, epochs=400, betas=(0.9, 0.999)\n",
      "Validation RMSE: 3.7023\n",
      "Iteration 9: Training NN with optimizer=sgd, learning_rate=0.01, epochs=800, betas=(0.85, 0.99)\n",
      "Validation RMSE: 2.9922\n",
      "Iteration 10: Training NN with optimizer=sgd, learning_rate=0.0001, epochs=100, betas=(0.85, 0.9999)\n",
      "Validation RMSE: 22.8558\n",
      "Iteration 11: Training NN with optimizer=sgd, learning_rate=0.001, epochs=200, betas=(0.95, 0.9999)\n",
      "Validation RMSE: 4.5526\n",
      "Iteration 12: Training NN with optimizer=sgd, learning_rate=0.0001, epochs=100, betas=(0.95, 0.999)\n",
      "Validation RMSE: 21.5246\n",
      "Iteration 13: Training NN with optimizer=sgd, learning_rate=0.0001, epochs=400, betas=(0.8, 0.999)\n",
      "Validation RMSE: 8.8277\n",
      "Iteration 14: Training NN with optimizer=sgd, learning_rate=0.001, epochs=400, betas=(0.9, 0.9999)\n",
      "Validation RMSE: 3.5316\n",
      "Iteration 15: Training NN with optimizer=sgd, learning_rate=0.001, epochs=200, betas=(0.8, 0.999)\n",
      "Validation RMSE: 4.6427\n",
      "Iteration 16: Training NN with optimizer=sgd, learning_rate=0.01, epochs=100, betas=(0.8, 0.999)\n",
      "Validation RMSE: 4.8695\n",
      "Iteration 17: Training NN with optimizer=sgd, learning_rate=0.1, epochs=200, betas=(0.9, 0.9999)\n",
      "Validation RMSE: nan\n",
      "Iteration 18: Training NN with optimizer=sgd, learning_rate=0.001, epochs=400, betas=(0.85, 0.99)\n",
      "Validation RMSE: 3.4430\n",
      "Iteration 19: Training NN with optimizer=sgd, learning_rate=0.001, epochs=800, betas=(0.85, 0.99)\n",
      "Validation RMSE: 3.2174\n",
      "Iteration 20: Training NN with optimizer=sgd, learning_rate=0.001, epochs=400, betas=(0.8, 0.999)\n",
      "Validation RMSE: 3.4696\n",
      "Iteration 21: Training NN with optimizer=sgd, learning_rate=0.1, epochs=1600, betas=(0.8, 0.999)\n",
      "Validation RMSE: 8.7249\n",
      "Iteration 22: Training NN with optimizer=sgd, learning_rate=0.1, epochs=1600, betas=(0.85, 0.999)\n",
      "Validation RMSE: nan\n",
      "Iteration 23: Training NN with optimizer=sgd, learning_rate=0.01, epochs=100, betas=(0.9, 0.99)\n",
      "Validation RMSE: 5.5128\n",
      "Iteration 24: Training NN with optimizer=sgd, learning_rate=0.0001, epochs=100, betas=(0.9, 0.99)\n",
      "Validation RMSE: 22.5995\n",
      "Iteration 25: Training NN with optimizer=sgd, learning_rate=0.1, epochs=800, betas=(0.8, 0.999)\n",
      "Validation RMSE: 8.7249\n",
      "Iteration 26: Training NN with optimizer=sgd, learning_rate=0.1, epochs=400, betas=(0.9, 0.9999)\n",
      "Validation RMSE: 8.7249\n",
      "Iteration 27: Training NN with optimizer=sgd, learning_rate=0.1, epochs=100, betas=(0.95, 0.999)\n",
      "Validation RMSE: 6663.7974\n",
      "Iteration 28: Training NN with optimizer=sgd, learning_rate=0.0001, epochs=1600, betas=(0.85, 0.999)\n",
      "Validation RMSE: 4.9471\n",
      "Iteration 29: Training NN with optimizer=sgd, learning_rate=0.0001, epochs=200, betas=(0.9, 0.9999)\n",
      "Validation RMSE: 18.0913\n",
      "Iteration 30: Training NN with optimizer=sgd, learning_rate=0.0001, epochs=400, betas=(0.95, 0.9999)\n",
      "Validation RMSE: 8.8382\n",
      "Iteration 31: Training NN with optimizer=sgd, learning_rate=0.01, epochs=800, betas=(0.9, 0.999)\n",
      "Validation RMSE: 2.8651\n",
      "Iteration 32: Training NN with optimizer=sgd, learning_rate=0.0001, epochs=200, betas=(0.9, 0.99)\n",
      "Validation RMSE: 19.3661\n",
      "Iteration 33: Training NN with optimizer=sgd, learning_rate=0.01, epochs=800, betas=(0.85, 0.99)\n",
      "Validation RMSE: 3.2387\n",
      "Iteration 34: Training NN with optimizer=sgd, learning_rate=0.001, epochs=200, betas=(0.8, 0.999)\n",
      "Validation RMSE: 4.7605\n",
      "Iteration 35: Training NN with optimizer=sgd, learning_rate=0.001, epochs=1600, betas=(0.95, 0.99)\n",
      "Validation RMSE: 2.8215\n",
      "Iteration 36: Training NN with optimizer=sgd, learning_rate=0.0001, epochs=800, betas=(0.8, 0.999)\n",
      "Validation RMSE: 6.6142\n",
      "Iteration 37: Training NN with optimizer=sgd, learning_rate=0.01, epochs=800, betas=(0.8, 0.999)\n",
      "Validation RMSE: 3.3655\n",
      "Iteration 38: Training NN with optimizer=sgd, learning_rate=0.01, epochs=800, betas=(0.95, 0.99)\n",
      "Validation RMSE: 3.2706\n",
      "Iteration 39: Training NN with optimizer=sgd, learning_rate=0.0001, epochs=400, betas=(0.95, 0.999)\n",
      "Validation RMSE: 8.3491\n",
      "Iteration 40: Training NN with optimizer=sgd, learning_rate=0.01, epochs=1600, betas=(0.9, 0.9999)\n",
      "Validation RMSE: 2.8563\n",
      "Iteration 41: Training NN with optimizer=sgd, learning_rate=0.001, epochs=400, betas=(0.95, 0.99)\n",
      "Validation RMSE: 3.5009\n",
      "Iteration 42: Training NN with optimizer=sgd, learning_rate=0.001, epochs=800, betas=(0.95, 0.9999)\n",
      "Validation RMSE: 3.1153\n",
      "Iteration 43: Training NN with optimizer=sgd, learning_rate=0.01, epochs=400, betas=(0.95, 0.99)\n",
      "Validation RMSE: 3.2964\n",
      "Iteration 44: Training NN with optimizer=sgd, learning_rate=0.001, epochs=400, betas=(0.85, 0.9999)\n",
      "Validation RMSE: 3.4874\n",
      "Iteration 45: Training NN with optimizer=sgd, learning_rate=0.1, epochs=400, betas=(0.95, 0.999)\n",
      "Validation RMSE: 8.7249\n",
      "Iteration 46: Training NN with optimizer=sgd, learning_rate=0.1, epochs=800, betas=(0.95, 0.999)\n",
      "Validation RMSE: 8.7249\n",
      "Iteration 47: Training NN with optimizer=sgd, learning_rate=0.001, epochs=400, betas=(0.9, 0.999)\n",
      "Validation RMSE: 3.5997\n",
      "Iteration 48: Training NN with optimizer=sgd, learning_rate=0.0001, epochs=800, betas=(0.9, 0.999)\n",
      "Validation RMSE: 6.4673\n",
      "Iteration 49: Training NN with optimizer=sgd, learning_rate=0.0001, epochs=800, betas=(0.85, 0.9999)\n",
      "Validation RMSE: 6.4984\n",
      "Iteration 50: Training NN with optimizer=sgd, learning_rate=0.0001, epochs=100, betas=(0.95, 0.9999)\n",
      "Validation RMSE: 22.7344\n",
      "Iteration 51: Training NN with optimizer=sgd, learning_rate=0.1, epochs=200, betas=(0.95, 0.9999)\n",
      "Validation RMSE: 8.7249\n",
      "Iteration 52: Training NN with optimizer=sgd, learning_rate=0.0001, epochs=400, betas=(0.85, 0.9999)\n",
      "Validation RMSE: 8.4140\n",
      "Iteration 53: Training NN with optimizer=sgd, learning_rate=0.0001, epochs=1600, betas=(0.85, 0.999)\n",
      "Validation RMSE: 5.0737\n",
      "Iteration 54: Training NN with optimizer=sgd, learning_rate=0.0001, epochs=800, betas=(0.85, 0.9999)\n",
      "Validation RMSE: 6.3546\n",
      "Iteration 55: Training NN with optimizer=sgd, learning_rate=0.0001, epochs=200, betas=(0.95, 0.99)\n",
      "Validation RMSE: 10.7751\n",
      "Iteration 56: Training NN with optimizer=sgd, learning_rate=0.0001, epochs=800, betas=(0.9, 0.99)\n",
      "Validation RMSE: 6.2871\n",
      "Iteration 57: Training NN with optimizer=sgd, learning_rate=0.0001, epochs=400, betas=(0.85, 0.99)\n",
      "Validation RMSE: 8.4776\n",
      "Iteration 58: Training NN with optimizer=sgd, learning_rate=0.001, epochs=800, betas=(0.95, 0.99)\n",
      "Validation RMSE: 3.0491\n",
      "Iteration 59: Training NN with optimizer=sgd, learning_rate=0.1, epochs=1600, betas=(0.8, 0.999)\n",
      "Validation RMSE: 8.7249\n",
      "Iteration 60: Training NN with optimizer=sgd, learning_rate=0.1, epochs=200, betas=(0.9, 0.99)\n",
      "Validation RMSE: 8.7249\n",
      "Iteration 61: Training NN with optimizer=sgd, learning_rate=0.001, epochs=800, betas=(0.85, 0.999)\n",
      "Validation RMSE: 3.1487\n",
      "Iteration 62: Training NN with optimizer=sgd, learning_rate=0.1, epochs=100, betas=(0.85, 0.99)\n",
      "Validation RMSE: 643548.3125\n",
      "Iteration 63: Training NN with optimizer=sgd, learning_rate=0.01, epochs=200, betas=(0.9, 0.9999)\n",
      "Validation RMSE: 4.4570\n",
      "Iteration 64: Training NN with optimizer=sgd, learning_rate=0.1, epochs=200, betas=(0.85, 0.999)\n",
      "Validation RMSE: nan\n",
      "Iteration 65: Training NN with optimizer=sgd, learning_rate=0.1, epochs=200, betas=(0.85, 0.9999)\n",
      "Validation RMSE: nan\n",
      "Iteration 66: Training NN with optimizer=sgd, learning_rate=0.001, epochs=100, betas=(0.9, 0.999)\n",
      "Validation RMSE: 6.1445\n",
      "Iteration 67: Training NN with optimizer=sgd, learning_rate=0.1, epochs=1600, betas=(0.85, 0.99)\n",
      "Validation RMSE: 8.7249\n",
      "Iteration 68: Training NN with optimizer=sgd, learning_rate=0.01, epochs=800, betas=(0.9, 0.999)\n",
      "Validation RMSE: 3.0747\n",
      "Iteration 69: Training NN with optimizer=sgd, learning_rate=0.0001, epochs=100, betas=(0.9, 0.9999)\n",
      "Validation RMSE: 22.5784\n",
      "Iteration 70: Training NN with optimizer=sgd, learning_rate=0.1, epochs=200, betas=(0.95, 0.99)\n",
      "Validation RMSE: 8.7249\n",
      "Iteration 71: Training NN with optimizer=sgd, learning_rate=0.001, epochs=100, betas=(0.95, 0.999)\n",
      "Validation RMSE: 5.9204\n",
      "Iteration 72: Training NN with optimizer=sgd, learning_rate=0.1, epochs=400, betas=(0.85, 0.999)\n",
      "Validation RMSE: 8.7249\n",
      "Iteration 73: Training NN with optimizer=sgd, learning_rate=0.01, epochs=200, betas=(0.85, 0.999)\n",
      "Validation RMSE: 4.3552\n",
      "Iteration 74: Training NN with optimizer=sgd, learning_rate=0.001, epochs=400, betas=(0.95, 0.999)\n",
      "Validation RMSE: 3.4797\n",
      "Iteration 75: Training NN with optimizer=sgd, learning_rate=0.1, epochs=200, betas=(0.85, 0.99)\n",
      "Validation RMSE: 8.7249\n",
      "Iteration 76: Training NN with optimizer=sgd, learning_rate=0.0001, epochs=400, betas=(0.85, 0.99)\n",
      "Validation RMSE: 8.6443\n",
      "Iteration 77: Training NN with optimizer=sgd, learning_rate=0.1, epochs=400, betas=(0.85, 0.999)\n",
      "Validation RMSE: 8.7249\n",
      "Iteration 78: Training NN with optimizer=sgd, learning_rate=0.001, epochs=200, betas=(0.95, 0.9999)\n",
      "Validation RMSE: 4.5194\n",
      "Iteration 79: Training NN with optimizer=sgd, learning_rate=0.1, epochs=200, betas=(0.85, 0.999)\n",
      "Validation RMSE: nan\n",
      "Iteration 80: Training NN with optimizer=sgd, learning_rate=0.001, epochs=400, betas=(0.9, 0.9999)\n",
      "Validation RMSE: 3.5303\n",
      "Iteration 81: Training NN with optimizer=sgd, learning_rate=0.01, epochs=1600, betas=(0.95, 0.999)\n",
      "Validation RMSE: 3.1613\n",
      "Iteration 82: Training NN with optimizer=sgd, learning_rate=0.0001, epochs=400, betas=(0.85, 0.9999)\n",
      "Validation RMSE: 8.2765\n",
      "Iteration 83: Training NN with optimizer=sgd, learning_rate=0.1, epochs=400, betas=(0.9, 0.9999)\n",
      "Validation RMSE: 8.7249\n",
      "Iteration 84: Training NN with optimizer=sgd, learning_rate=0.1, epochs=400, betas=(0.85, 0.99)\n",
      "Validation RMSE: nan\n",
      "Iteration 85: Training NN with optimizer=sgd, learning_rate=0.01, epochs=1600, betas=(0.9, 0.99)\n",
      "Validation RMSE: 2.9187\n",
      "Iteration 86: Training NN with optimizer=sgd, learning_rate=0.1, epochs=200, betas=(0.9, 0.99)\n",
      "Validation RMSE: nan\n",
      "Iteration 87: Training NN with optimizer=sgd, learning_rate=0.1, epochs=400, betas=(0.95, 0.9999)\n",
      "Validation RMSE: nan\n",
      "Iteration 88: Training NN with optimizer=sgd, learning_rate=0.0001, epochs=1600, betas=(0.9, 0.9999)\n",
      "Validation RMSE: 5.1366\n",
      "Iteration 89: Training NN with optimizer=sgd, learning_rate=0.001, epochs=100, betas=(0.9, 0.99)\n",
      "Validation RMSE: 6.2510\n",
      "Iteration 90: Training NN with optimizer=sgd, learning_rate=0.1, epochs=1600, betas=(0.95, 0.9999)\n",
      "Validation RMSE: 8.7249\n",
      "Iteration 91: Training NN with optimizer=sgd, learning_rate=0.01, epochs=800, betas=(0.9, 0.9999)\n",
      "Validation RMSE: 2.8746\n",
      "Iteration 92: Training NN with optimizer=sgd, learning_rate=0.1, epochs=1600, betas=(0.85, 0.99)\n",
      "Validation RMSE: 8.7249\n",
      "Iteration 93: Training NN with optimizer=sgd, learning_rate=0.1, epochs=1600, betas=(0.8, 0.999)\n",
      "Validation RMSE: nan\n",
      "Iteration 94: Training NN with optimizer=sgd, learning_rate=0.1, epochs=400, betas=(0.95, 0.99)\n",
      "Validation RMSE: 8.7249\n",
      "Iteration 95: Training NN with optimizer=sgd, learning_rate=0.0001, epochs=800, betas=(0.85, 0.9999)\n",
      "Validation RMSE: 6.5129\n",
      "Iteration 96: Training NN with optimizer=sgd, learning_rate=0.001, epochs=100, betas=(0.95, 0.9999)\n",
      "Validation RMSE: 6.2088\n",
      "Iteration 97: Training NN with optimizer=sgd, learning_rate=0.01, epochs=1600, betas=(0.95, 0.999)\n",
      "Validation RMSE: 2.7474\n",
      "Iteration 98: Training NN with optimizer=sgd, learning_rate=0.01, epochs=100, betas=(0.85, 0.999)\n",
      "Validation RMSE: 5.8654\n",
      "Iteration 99: Training NN with optimizer=sgd, learning_rate=0.0001, epochs=100, betas=(0.9, 0.9999)\n",
      "Validation RMSE: 22.3633\n",
      "Iteration 100: Training NN with optimizer=sgd, learning_rate=0.001, epochs=800, betas=(0.85, 0.99)\n",
      "Validation RMSE: 3.0438\n",
      "Best hyperparameters: {'optimizer_type': 'sgd', 'learning_rate': 0.01, 'epochs': 1600, 'betas': (0.95, 0.999)}, Best RMSE: 2.7474\n",
      "Iteration 1: Training NN with optimizer=adam, learning_rate=0.1, epochs=400, betas=(0.85, 0.999)\n",
      "Validation RMSE: 2.8199\n",
      "Iteration 2: Training NN with optimizer=adam, learning_rate=0.01, epochs=1600, betas=(0.95, 0.999)\n",
      "Validation RMSE: 2.9709\n",
      "Iteration 3: Training NN with optimizer=adam, learning_rate=0.1, epochs=400, betas=(0.9, 0.999)\n",
      "Validation RMSE: 2.7554\n",
      "Iteration 4: Training NN with optimizer=adam, learning_rate=0.1, epochs=1600, betas=(0.9, 0.99)\n",
      "Validation RMSE: 2.9289\n",
      "Iteration 5: Training NN with optimizer=adam, learning_rate=0.01, epochs=100, betas=(0.95, 0.9999)\n",
      "Validation RMSE: 5.7356\n",
      "Iteration 6: Training NN with optimizer=adam, learning_rate=0.1, epochs=800, betas=(0.9, 0.9999)\n",
      "Validation RMSE: 2.9456\n",
      "Iteration 7: Training NN with optimizer=adam, learning_rate=0.001, epochs=800, betas=(0.9, 0.9999)\n",
      "Validation RMSE: 3.3624\n",
      "Iteration 8: Training NN with optimizer=adam, learning_rate=0.01, epochs=400, betas=(0.95, 0.9999)\n",
      "Validation RMSE: 2.7998\n",
      "Iteration 9: Training NN with optimizer=adam, learning_rate=0.001, epochs=1600, betas=(0.9, 0.999)\n",
      "Validation RMSE: 2.8764\n",
      "Iteration 10: Training NN with optimizer=adam, learning_rate=0.001, epochs=1600, betas=(0.9, 0.9999)\n",
      "Validation RMSE: 2.9551\n",
      "Iteration 11: Training NN with optimizer=adam, learning_rate=0.1, epochs=800, betas=(0.95, 0.9999)\n",
      "Validation RMSE: 2.9831\n",
      "Iteration 12: Training NN with optimizer=adam, learning_rate=0.1, epochs=400, betas=(0.9, 0.99)\n",
      "Validation RMSE: 4.9344\n",
      "Iteration 13: Training NN with optimizer=adam, learning_rate=0.0001, epochs=400, betas=(0.85, 0.99)\n",
      "Validation RMSE: 20.4132\n",
      "Iteration 14: Training NN with optimizer=adam, learning_rate=0.1, epochs=800, betas=(0.9, 0.999)\n",
      "Validation RMSE: 3.0112\n",
      "Iteration 15: Training NN with optimizer=adam, learning_rate=0.01, epochs=200, betas=(0.9, 0.999)\n",
      "Validation RMSE: 3.0051\n",
      "Iteration 16: Training NN with optimizer=adam, learning_rate=0.1, epochs=400, betas=(0.9, 0.999)\n",
      "Validation RMSE: 2.9926\n",
      "Iteration 17: Training NN with optimizer=adam, learning_rate=0.1, epochs=1600, betas=(0.85, 0.9999)\n",
      "Validation RMSE: 8.7249\n",
      "Iteration 18: Training NN with optimizer=adam, learning_rate=0.001, epochs=1600, betas=(0.95, 0.9999)\n",
      "Validation RMSE: 2.8445\n",
      "Iteration 19: Training NN with optimizer=adam, learning_rate=0.1, epochs=800, betas=(0.9, 0.999)\n",
      "Validation RMSE: 2.4659\n",
      "Iteration 20: Training NN with optimizer=adam, learning_rate=0.01, epochs=200, betas=(0.95, 0.9999)\n",
      "Validation RMSE: 3.4096\n",
      "Iteration 21: Training NN with optimizer=adam, learning_rate=0.1, epochs=200, betas=(0.95, 0.9999)\n",
      "Validation RMSE: 2.6900\n",
      "Iteration 22: Training NN with optimizer=adam, learning_rate=0.1, epochs=400, betas=(0.85, 0.999)\n",
      "Validation RMSE: 3.0457\n",
      "Iteration 23: Training NN with optimizer=adam, learning_rate=0.001, epochs=100, betas=(0.95, 0.999)\n",
      "Validation RMSE: 11.5228\n",
      "Iteration 24: Training NN with optimizer=adam, learning_rate=0.0001, epochs=400, betas=(0.85, 0.9999)\n",
      "Validation RMSE: 18.0948\n",
      "Iteration 25: Training NN with optimizer=adam, learning_rate=0.1, epochs=400, betas=(0.95, 0.99)\n",
      "Validation RMSE: 3.0943\n",
      "Iteration 26: Training NN with optimizer=adam, learning_rate=0.01, epochs=1600, betas=(0.95, 0.999)\n",
      "Validation RMSE: 2.6859\n",
      "Iteration 27: Training NN with optimizer=adam, learning_rate=0.1, epochs=100, betas=(0.95, 0.999)\n",
      "Validation RMSE: 8.9210\n",
      "Iteration 28: Training NN with optimizer=adam, learning_rate=0.1, epochs=400, betas=(0.85, 0.999)\n",
      "Validation RMSE: 3.0741\n",
      "Iteration 29: Training NN with optimizer=adam, learning_rate=0.01, epochs=800, betas=(0.95, 0.999)\n",
      "Validation RMSE: 2.9772\n",
      "Iteration 30: Training NN with optimizer=adam, learning_rate=0.001, epochs=1600, betas=(0.85, 0.99)\n",
      "Validation RMSE: 2.8978\n",
      "Iteration 31: Training NN with optimizer=adam, learning_rate=0.001, epochs=800, betas=(0.95, 0.9999)\n",
      "Validation RMSE: 3.3041\n",
      "Iteration 32: Training NN with optimizer=adam, learning_rate=0.01, epochs=200, betas=(0.95, 0.9999)\n",
      "Validation RMSE: 3.3719\n",
      "Iteration 33: Training NN with optimizer=adam, learning_rate=0.001, epochs=100, betas=(0.9, 0.999)\n",
      "Validation RMSE: 10.5786\n",
      "Iteration 34: Training NN with optimizer=adam, learning_rate=0.01, epochs=400, betas=(0.8, 0.999)\n",
      "Validation RMSE: 3.0137\n",
      "Iteration 35: Training NN with optimizer=adam, learning_rate=0.001, epochs=200, betas=(0.9, 0.9999)\n",
      "Validation RMSE: 6.9479\n",
      "Iteration 36: Training NN with optimizer=adam, learning_rate=0.1, epochs=200, betas=(0.85, 0.999)\n",
      "Validation RMSE: 2.7969\n",
      "Iteration 37: Training NN with optimizer=adam, learning_rate=0.001, epochs=400, betas=(0.85, 0.999)\n",
      "Validation RMSE: 4.0748\n",
      "Iteration 38: Training NN with optimizer=adam, learning_rate=0.1, epochs=1600, betas=(0.9, 0.9999)\n",
      "Validation RMSE: 2.6928\n",
      "Iteration 39: Training NN with optimizer=adam, learning_rate=0.01, epochs=200, betas=(0.9, 0.9999)\n",
      "Validation RMSE: 2.8988\n",
      "Iteration 40: Training NN with optimizer=adam, learning_rate=0.1, epochs=800, betas=(0.95, 0.99)\n",
      "Validation RMSE: 2.9418\n",
      "Iteration 41: Training NN with optimizer=adam, learning_rate=0.1, epochs=800, betas=(0.85, 0.999)\n",
      "Validation RMSE: 2.8227\n",
      "Iteration 42: Training NN with optimizer=adam, learning_rate=0.1, epochs=1600, betas=(0.9, 0.99)\n",
      "Validation RMSE: 2.5072\n",
      "Iteration 43: Training NN with optimizer=adam, learning_rate=0.0001, epochs=200, betas=(0.95, 0.9999)\n",
      "Validation RMSE: 23.2338\n",
      "Iteration 44: Training NN with optimizer=adam, learning_rate=0.1, epochs=400, betas=(0.95, 0.99)\n",
      "Validation RMSE: 2.9419\n",
      "Iteration 45: Training NN with optimizer=adam, learning_rate=0.0001, epochs=1600, betas=(0.95, 0.99)\n",
      "Validation RMSE: 8.0735\n",
      "Iteration 46: Training NN with optimizer=adam, learning_rate=0.1, epochs=400, betas=(0.9, 0.999)\n",
      "Validation RMSE: 2.6656\n",
      "Iteration 47: Training NN with optimizer=adam, learning_rate=0.01, epochs=200, betas=(0.9, 0.999)\n",
      "Validation RMSE: 2.9620\n",
      "Iteration 48: Training NN with optimizer=adam, learning_rate=0.0001, epochs=1600, betas=(0.9, 0.9999)\n",
      "Validation RMSE: 7.1472\n",
      "Iteration 49: Training NN with optimizer=adam, learning_rate=0.01, epochs=800, betas=(0.95, 0.9999)\n",
      "Validation RMSE: 2.6508\n",
      "Iteration 50: Training NN with optimizer=adam, learning_rate=0.001, epochs=400, betas=(0.9, 0.99)\n",
      "Validation RMSE: 4.7383\n",
      "Iteration 51: Training NN with optimizer=adam, learning_rate=0.01, epochs=1600, betas=(0.9, 0.99)\n",
      "Validation RMSE: 3.0100\n",
      "Iteration 52: Training NN with optimizer=adam, learning_rate=0.001, epochs=1600, betas=(0.95, 0.9999)\n",
      "Validation RMSE: 2.8973\n",
      "Iteration 53: Training NN with optimizer=adam, learning_rate=0.1, epochs=200, betas=(0.95, 0.99)\n",
      "Validation RMSE: 2.8968\n",
      "Iteration 54: Training NN with optimizer=adam, learning_rate=0.1, epochs=800, betas=(0.95, 0.9999)\n",
      "Validation RMSE: 2.7090\n",
      "Iteration 55: Training NN with optimizer=adam, learning_rate=0.0001, epochs=1600, betas=(0.95, 0.99)\n",
      "Validation RMSE: 7.4782\n",
      "Iteration 56: Training NN with optimizer=adam, learning_rate=0.1, epochs=200, betas=(0.85, 0.99)\n",
      "Validation RMSE: 6.0883\n",
      "Iteration 57: Training NN with optimizer=adam, learning_rate=0.0001, epochs=100, betas=(0.85, 0.9999)\n",
      "Validation RMSE: 23.6406\n",
      "Iteration 58: Training NN with optimizer=adam, learning_rate=0.001, epochs=400, betas=(0.9, 0.9999)\n",
      "Validation RMSE: 5.6129\n",
      "Iteration 59: Training NN with optimizer=adam, learning_rate=0.0001, epochs=1600, betas=(0.9, 0.999)\n",
      "Validation RMSE: 7.5632\n",
      "Iteration 60: Training NN with optimizer=adam, learning_rate=0.001, epochs=1600, betas=(0.95, 0.9999)\n",
      "Validation RMSE: 2.7259\n",
      "Iteration 61: Training NN with optimizer=adam, learning_rate=0.1, epochs=400, betas=(0.95, 0.999)\n",
      "Validation RMSE: 2.6922\n",
      "Iteration 62: Training NN with optimizer=adam, learning_rate=0.1, epochs=200, betas=(0.85, 0.999)\n",
      "Validation RMSE: 2.7488\n",
      "Iteration 63: Training NN with optimizer=adam, learning_rate=0.0001, epochs=1600, betas=(0.85, 0.9999)\n",
      "Validation RMSE: 8.0608\n",
      "Iteration 64: Training NN with optimizer=adam, learning_rate=0.001, epochs=800, betas=(0.85, 0.99)\n",
      "Validation RMSE: 2.8459\n",
      "Iteration 65: Training NN with optimizer=adam, learning_rate=0.001, epochs=200, betas=(0.95, 0.9999)\n",
      "Validation RMSE: 7.1720\n",
      "Iteration 66: Training NN with optimizer=adam, learning_rate=0.1, epochs=800, betas=(0.9, 0.999)\n",
      "Validation RMSE: 2.6168\n",
      "Iteration 67: Training NN with optimizer=adam, learning_rate=0.1, epochs=1600, betas=(0.85, 0.9999)\n",
      "Validation RMSE: 3.0957\n",
      "Iteration 68: Training NN with optimizer=adam, learning_rate=0.001, epochs=200, betas=(0.9, 0.999)\n",
      "Validation RMSE: 7.0879\n",
      "Iteration 69: Training NN with optimizer=adam, learning_rate=0.01, epochs=800, betas=(0.8, 0.999)\n",
      "Validation RMSE: 2.9116\n",
      "Iteration 70: Training NN with optimizer=adam, learning_rate=0.0001, epochs=100, betas=(0.95, 0.99)\n",
      "Validation RMSE: 23.8654\n",
      "Iteration 71: Training NN with optimizer=adam, learning_rate=0.0001, epochs=800, betas=(0.95, 0.999)\n",
      "Validation RMSE: 11.5177\n",
      "Iteration 72: Training NN with optimizer=adam, learning_rate=0.01, epochs=100, betas=(0.95, 0.999)\n",
      "Validation RMSE: 5.4423\n",
      "Iteration 73: Training NN with optimizer=adam, learning_rate=0.0001, epochs=1600, betas=(0.9, 0.99)\n",
      "Validation RMSE: 7.2490\n",
      "Iteration 74: Training NN with optimizer=adam, learning_rate=0.0001, epochs=800, betas=(0.95, 0.999)\n",
      "Validation RMSE: 10.8715\n",
      "Iteration 75: Training NN with optimizer=adam, learning_rate=0.01, epochs=400, betas=(0.85, 0.9999)\n",
      "Validation RMSE: 3.1050\n",
      "Iteration 76: Training NN with optimizer=adam, learning_rate=0.001, epochs=100, betas=(0.85, 0.9999)\n",
      "Validation RMSE: 10.7947\n",
      "Iteration 77: Training NN with optimizer=adam, learning_rate=0.1, epochs=100, betas=(0.9, 0.9999)\n",
      "Validation RMSE: 3.0125\n",
      "Iteration 78: Training NN with optimizer=adam, learning_rate=0.01, epochs=100, betas=(0.95, 0.9999)\n",
      "Validation RMSE: 5.6008\n",
      "Iteration 79: Training NN with optimizer=adam, learning_rate=0.001, epochs=100, betas=(0.95, 0.9999)\n",
      "Validation RMSE: 10.9159\n",
      "Iteration 80: Training NN with optimizer=adam, learning_rate=0.001, epochs=200, betas=(0.85, 0.9999)\n",
      "Validation RMSE: 6.7475\n",
      "Iteration 81: Training NN with optimizer=adam, learning_rate=0.01, epochs=800, betas=(0.9, 0.999)\n",
      "Validation RMSE: 2.8449\n",
      "Iteration 82: Training NN with optimizer=adam, learning_rate=0.0001, epochs=200, betas=(0.85, 0.99)\n",
      "Validation RMSE: 23.1059\n",
      "Iteration 83: Training NN with optimizer=adam, learning_rate=0.01, epochs=400, betas=(0.9, 0.999)\n",
      "Validation RMSE: 3.0034\n",
      "Iteration 84: Training NN with optimizer=adam, learning_rate=0.001, epochs=100, betas=(0.9, 0.999)\n",
      "Validation RMSE: 10.3061\n",
      "Iteration 85: Training NN with optimizer=adam, learning_rate=0.1, epochs=1600, betas=(0.9, 0.99)\n",
      "Validation RMSE: 2.8744\n",
      "Iteration 86: Training NN with optimizer=adam, learning_rate=0.1, epochs=200, betas=(0.85, 0.99)\n",
      "Validation RMSE: 3.0655\n",
      "Iteration 87: Training NN with optimizer=adam, learning_rate=0.0001, epochs=100, betas=(0.95, 0.9999)\n",
      "Validation RMSE: 23.7674\n",
      "Iteration 88: Training NN with optimizer=adam, learning_rate=0.0001, epochs=200, betas=(0.9, 0.999)\n",
      "Validation RMSE: 23.1455\n",
      "Iteration 89: Training NN with optimizer=adam, learning_rate=0.01, epochs=100, betas=(0.85, 0.99)\n",
      "Validation RMSE: 3.3002\n",
      "Iteration 90: Training NN with optimizer=adam, learning_rate=0.01, epochs=100, betas=(0.85, 0.999)\n",
      "Validation RMSE: 3.3934\n",
      "Iteration 91: Training NN with optimizer=adam, learning_rate=0.1, epochs=800, betas=(0.95, 0.99)\n",
      "Validation RMSE: 2.6011\n",
      "Iteration 92: Training NN with optimizer=adam, learning_rate=0.01, epochs=800, betas=(0.85, 0.9999)\n",
      "Validation RMSE: 2.9448\n",
      "Iteration 93: Training NN with optimizer=adam, learning_rate=0.1, epochs=800, betas=(0.95, 0.99)\n",
      "Validation RMSE: 2.8151\n",
      "Iteration 94: Training NN with optimizer=adam, learning_rate=0.0001, epochs=800, betas=(0.9, 0.999)\n",
      "Validation RMSE: 9.6221\n",
      "Iteration 95: Training NN with optimizer=adam, learning_rate=0.0001, epochs=1600, betas=(0.95, 0.9999)\n",
      "Validation RMSE: 7.7935\n",
      "Iteration 96: Training NN with optimizer=adam, learning_rate=0.0001, epochs=1600, betas=(0.9, 0.99)\n",
      "Validation RMSE: 7.9725\n",
      "Iteration 97: Training NN with optimizer=adam, learning_rate=0.001, epochs=200, betas=(0.95, 0.99)\n",
      "Validation RMSE: 8.2554\n",
      "Iteration 98: Training NN with optimizer=adam, learning_rate=0.001, epochs=1600, betas=(0.9, 0.99)\n",
      "Validation RMSE: 2.8250\n",
      "Iteration 99: Training NN with optimizer=adam, learning_rate=0.1, epochs=200, betas=(0.9, 0.99)\n",
      "Validation RMSE: 3.3819\n",
      "Iteration 100: Training NN with optimizer=adam, learning_rate=0.1, epochs=100, betas=(0.85, 0.9999)\n",
      "Validation RMSE: 2.8856\n",
      "Best hyperparameters: {'optimizer_type': 'adam', 'learning_rate': 0.1, 'epochs': 800, 'betas': (0.9, 0.999)}, Best RMSE: 2.4659\n"
     ]
    }
   ],
   "source": [
    "search_iterations = 100\n",
    "parameters = {}\n",
    "\n",
    "for model in ['td', 'nn']:\n",
    "    param_grid = grids[model]\n",
    "    for optimizer in ['sgd', 'adam']:\n",
    "        best_params = random_search(model, X_train, y_train, X_test, y_test, param_grid, search_iterations, optimizer)\n",
    "        parameters[f'{model}_{optimizer}'] = best_params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'optimizer_type': 'sgd', 'learning_rate': 0.001, 'gamma': 0, 'epsilon': 1e-07, 'n_iter': 100000.0, 'betas': (0.8, 0.999)}\n",
      "{'optimizer_type': 'adam', 'learning_rate': 0.001, 'gamma': 0, 'epsilon': 1e-06, 'n_iter': 100000.0, 'betas': (0.85, 0.999)}\n",
      "{'optimizer_type': 'sgd', 'learning_rate': 0.01, 'epochs': 1600, 'betas': (0.95, 0.999)}\n",
      "{'optimizer_type': 'adam', 'learning_rate': 0.1, 'epochs': 800, 'betas': (0.9, 0.999)}\n"
     ]
    }
   ],
   "source": [
    "for i in parameters.values():\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.NeuralNet import TwoLayerFCNN_Adam, TwoLayerFCNN_SGD\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the housing data\n",
    "housedata = np.loadtxt('data\\\\readyhousedata.txt', delimiter=',')\n",
    "\n",
    "# Separate features and target\n",
    "X = housedata[:, :-1]\n",
    "y = housedata[:, -1]\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# Split dara\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "# Get the number of samples and features from the training set\n",
    "n_samples, n_features = X_train.shape\n",
    "hidden_size = 64\n",
    "batch_size = 32\n",
    "\n",
    "# Data loader\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Create test data loader for evaluation\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "num_epochs = 100\n",
    "\n",
    "model = TwoLayerFCNN_Adam(\n",
    "    batch_size=batch_size,\n",
    "    lr=lr,\n",
    "    n_epochs=num_epochs,\n",
    "    input_size=n_features, \n",
    "    hidden_size=hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 554.4724\n",
      "Epoch [2/100], Loss: 401.1476\n",
      "Epoch [3/100], Loss: 175.0218\n",
      "Epoch [4/100], Loss: 109.9056\n",
      "Epoch [5/100], Loss: 97.7367\n",
      "Epoch [6/100], Loss: 90.9840\n",
      "Epoch [7/100], Loss: 81.4818\n",
      "Epoch [8/100], Loss: 75.4384\n",
      "Epoch [9/100], Loss: 71.6603\n",
      "Epoch [10/100], Loss: 66.1212\n",
      "Epoch [11/100], Loss: 62.6897\n",
      "Epoch [12/100], Loss: 60.3871\n",
      "Epoch [13/100], Loss: 57.5313\n",
      "Epoch [14/100], Loss: 55.5950\n",
      "Epoch [15/100], Loss: 53.1579\n",
      "Epoch [16/100], Loss: 52.9409\n",
      "Epoch [17/100], Loss: 50.6178\n",
      "Epoch [18/100], Loss: 48.8775\n",
      "Epoch [19/100], Loss: 48.0970\n",
      "Epoch [20/100], Loss: 47.3260\n",
      "Epoch [21/100], Loss: 46.6913\n",
      "Epoch [22/100], Loss: 45.1547\n",
      "Epoch [23/100], Loss: 45.1668\n",
      "Epoch [24/100], Loss: 43.6520\n",
      "Epoch [25/100], Loss: 43.3445\n",
      "Epoch [26/100], Loss: 42.2684\n",
      "Epoch [27/100], Loss: 41.0642\n",
      "Epoch [28/100], Loss: 40.1229\n",
      "Epoch [29/100], Loss: 39.7257\n",
      "Epoch [30/100], Loss: 38.9296\n",
      "Epoch [31/100], Loss: 40.0861\n",
      "Epoch [32/100], Loss: 37.8514\n",
      "Epoch [33/100], Loss: 37.6377\n",
      "Epoch [34/100], Loss: 37.0693\n",
      "Epoch [35/100], Loss: 36.8637\n",
      "Epoch [36/100], Loss: 35.3840\n",
      "Epoch [37/100], Loss: 35.6999\n",
      "Epoch [38/100], Loss: 35.5416\n",
      "Epoch [39/100], Loss: 35.0865\n",
      "Epoch [40/100], Loss: 33.6368\n",
      "Epoch [41/100], Loss: 33.2391\n",
      "Epoch [42/100], Loss: 32.7473\n",
      "Epoch [43/100], Loss: 32.6713\n",
      "Epoch [44/100], Loss: 31.7790\n",
      "Epoch [45/100], Loss: 31.8473\n",
      "Epoch [46/100], Loss: 31.1930\n",
      "Epoch [47/100], Loss: 30.9467\n",
      "Epoch [48/100], Loss: 30.8400\n",
      "Epoch [49/100], Loss: 29.5999\n",
      "Epoch [50/100], Loss: 29.2079\n",
      "Epoch [51/100], Loss: 29.3295\n",
      "Epoch [52/100], Loss: 28.8508\n",
      "Epoch [53/100], Loss: 28.4778\n",
      "Epoch [54/100], Loss: 28.3666\n",
      "Epoch [55/100], Loss: 27.7532\n",
      "Epoch [56/100], Loss: 27.8986\n",
      "Epoch [57/100], Loss: 27.7090\n",
      "Epoch [58/100], Loss: 27.1107\n",
      "Epoch [59/100], Loss: 26.8265\n",
      "Epoch [60/100], Loss: 28.8771\n",
      "Epoch [61/100], Loss: 26.4369\n",
      "Epoch [62/100], Loss: 26.9264\n",
      "Epoch [63/100], Loss: 26.5363\n",
      "Epoch [64/100], Loss: 25.8492\n",
      "Epoch [65/100], Loss: 26.1810\n",
      "Epoch [66/100], Loss: 25.5344\n",
      "Epoch [67/100], Loss: 25.8682\n",
      "Epoch [68/100], Loss: 25.6974\n",
      "Epoch [69/100], Loss: 25.3078\n",
      "Epoch [70/100], Loss: 25.0059\n",
      "Epoch [71/100], Loss: 25.3187\n",
      "Epoch [72/100], Loss: 25.3016\n",
      "Epoch [73/100], Loss: 25.0505\n",
      "Epoch [74/100], Loss: 24.3015\n",
      "Epoch [75/100], Loss: 23.9931\n",
      "Epoch [76/100], Loss: 24.2824\n",
      "Epoch [77/100], Loss: 24.9933\n",
      "Epoch [78/100], Loss: 25.1706\n",
      "Epoch [79/100], Loss: 23.7197\n",
      "Epoch [80/100], Loss: 23.6363\n",
      "Epoch [81/100], Loss: 24.2408\n",
      "Epoch [82/100], Loss: 23.4558\n",
      "Epoch [83/100], Loss: 23.2904\n",
      "Epoch [84/100], Loss: 23.2558\n",
      "Epoch [85/100], Loss: 23.2867\n",
      "Epoch [86/100], Loss: 22.9215\n",
      "Epoch [87/100], Loss: 23.0047\n",
      "Epoch [88/100], Loss: 23.1685\n",
      "Epoch [89/100], Loss: 23.0650\n",
      "Epoch [90/100], Loss: 22.8856\n",
      "Epoch [91/100], Loss: 23.0932\n",
      "Epoch [92/100], Loss: 22.9228\n",
      "Epoch [93/100], Loss: 23.6934\n",
      "Epoch [94/100], Loss: 23.8226\n",
      "Epoch [95/100], Loss: 22.3226\n",
      "Epoch [96/100], Loss: 22.3616\n",
      "Epoch [97/100], Loss: 22.6201\n",
      "Epoch [98/100], Loss: 22.4221\n",
      "Epoch [99/100], Loss: 22.2788\n",
      "Epoch [100/100], Loss: 22.2108\n"
     ]
    }
   ],
   "source": [
    "model.fit_sgd(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.286197662353516"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESET_FLAG = False\n",
    "\n",
    "if RESET_FLAG:\n",
    "    model.reset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
